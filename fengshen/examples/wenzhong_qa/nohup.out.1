++ date +%s
+ run_ts=1672637296
++ run_ts
./finetune_bloomz_combine_highinter_template_suspence_long_only.sh: line 16: run_ts: command not found
+ echo 'RUN TS: '
RUN TS: 
++ date
+ echo 'START TIME: Mon Jan  2 13:28:16 CST 2023'
START TIME: Mon Jan  2 13:28:16 CST 2023
+ MICRO_BATCH_SIZE=1
+ ROOT_DIR=/home/ubuntu/cloudfs_nfs/saved_models/deep_speed_experiments/bloomz/combined_highinter_template_suspence_long_only
+ '[' '!' -d /home/ubuntu/cloudfs_nfs/saved_models/deep_speed_experiments/bloomz/combined_highinter_template_suspence_long_only ']'
+ mkdir -p /home/ubuntu/cloudfs_nfs/saved_models/deep_speed_experiments/bloomz/combined_highinter_template_suspence_long_only
+ echo /home/ubuntu/cloudfs_nfs/saved_models/deep_speed_experiments/bloomz/combined_highinter_template_suspence_long_only 'created!!!!!!!!!!!!!!'
/home/ubuntu/cloudfs_nfs/saved_models/deep_speed_experiments/bloomz/combined_highinter_template_suspence_long_only created!!!!!!!!!!!!!!
+ ZERO_STAGE=2
+ config_json=/home/ubuntu/cloudfs_nfs/saved_models/deep_speed_experiments/bloomz/combined_highinter_template_suspence_long_only/training_config.json
+ export MASTER_PORT=35791
+ MASTER_PORT=35791
+ cat
+ export PL_DEEPSPEED_CONFIG_PATH=/home/ubuntu/cloudfs_nfs/saved_models/deep_speed_experiments/bloomz/combined_highinter_template_suspence_long_only/training_config.json
+ PL_DEEPSPEED_CONFIG_PATH=/home/ubuntu/cloudfs_nfs/saved_models/deep_speed_experiments/bloomz/combined_highinter_template_suspence_long_only/training_config.json
+ checkpoint_path=/home/ubuntu/cloudfs_nfs/saved_models/deep_speed_experiments/bloomz/combined_highinter_template_suspence_long_only/ckpt_1672637296
+ export TORCH_EXTENSIONS_DIR=/home/ubuntu/cloudfs/torch_extendsions
+ TORCH_EXTENSIONS_DIR=/home/ubuntu/cloudfs/torch_extendsions
+ TRAINER_ARGS='
    --max_epochs 50     --accumulate_grad_batches 8     --gpus 4     --num_nodes 1     --strategy deepspeed_stage_2     --default_root_dir /home/ubuntu/cloudfs_nfs/saved_models/deep_speed_experiments/bloomz/combined_highinter_template_suspence_long_only     --dirpath /home/ubuntu/cloudfs_nfs/saved_models/deep_speed_experiments/bloomz/combined_highinter_template_suspence_long_only/ckpt_1672637296     --save_top_k 5     --monitor train_loss     --mode min     --save_last     --check_val_every_n_epoch 1 '
+ DATA_DIR=/home/ubuntu/cloudfs/ghost_data/merge_all_title_content/
+ train_data_file=/home/ubuntu/cloudfs/ghost_data/combined_high_inter_template_suspences/combined_high_inter_template_suspences_long_only_train_1229_1672366480.csv
+ val_data_file=/home/ubuntu/cloudfs/ghost_data/combined_high_inter_template_suspences/combined_high_inter_template_suspences_long_only_val_1229_1672366480.csv
+ train_data_file=/home/ubuntu/cloudfs/ghost_data/combined_high_inter_template_suspences/combined_high_inter_template_suspences_long_only_train_sample_1229_1672366480.csv
+ val_data_file=/home/ubuntu/cloudfs/ghost_data/combined_high_inter_template_suspences/combined_high_inter_template_suspences_long_only_val_sample_1229_1672366480.csv
+ DATA_ARGS='
    --data_dir /home/ubuntu/cloudfs/ghost_data/merge_all_title_content/     --train_batchsize 1     --valid_batchsize 1     --train_data  /home/ubuntu/cloudfs/ghost_data/combined_high_inter_template_suspences/combined_high_inter_template_suspences_long_only_train_sample_1229_1672366480.csv     --valid_data  /home/ubuntu/cloudfs/ghost_data/combined_high_inter_template_suspences/combined_high_inter_template_suspences_long_only_val_sample_1229_1672366480.csv     --test_data  /home/ubuntu/cloudfs/ghost_data/combined_high_inter_template_suspences/combined_high_inter_template_suspences_long_only_val_sample_1229_1672366480.csv     --max_seq_length 500 '
+ PRETRAINED_MODEL_PATH=/home/ubuntu/cloudfs/saved_models/bigscience/bloomz-3b
+ MODEL_ARGS='
    --pretrained_model_path /home/ubuntu/cloudfs/saved_models/bigscience/bloomz-3b     --enable_progress_bar True     --output_save_path /home/ubuntu/cloudfs_nfs/saved_models/deep_speed_experiments/bloomz/combined_highinter_template_suspence_long_only/predict.json     --learning_rate 1e-4     --weight_decay 0.1     --warmup 0.01     --run_ts 1672637296 '
+ SCRIPTS_PATH=/home/ubuntu/cloudfs/Fengshenbang-LM/fengshen/examples/wenzhong_qa/finetune_bloomz_combined.py
+ export 'CMD=     /home/ubuntu/cloudfs/Fengshenbang-LM/fengshen/examples/wenzhong_qa/finetune_bloomz_combined.py     
    --max_epochs 50     --accumulate_grad_batches 8     --gpus 4     --num_nodes 1     --strategy deepspeed_stage_2     --default_root_dir /home/ubuntu/cloudfs_nfs/saved_models/deep_speed_experiments/bloomz/combined_highinter_template_suspence_long_only     --dirpath /home/ubuntu/cloudfs_nfs/saved_models/deep_speed_experiments/bloomz/combined_highinter_template_suspence_long_only/ckpt_1672637296     --save_top_k 5     --monitor train_loss     --mode min     --save_last     --check_val_every_n_epoch 1      
    --pretrained_model_path /home/ubuntu/cloudfs/saved_models/bigscience/bloomz-3b     --enable_progress_bar True     --output_save_path /home/ubuntu/cloudfs_nfs/saved_models/deep_speed_experiments/bloomz/combined_highinter_template_suspence_long_only/predict.json     --learning_rate 1e-4     --weight_decay 0.1     --warmup 0.01     --run_ts 1672637296      
    --data_dir /home/ubuntu/cloudfs/ghost_data/merge_all_title_content/     --train_batchsize 1     --valid_batchsize 1     --train_data  /home/ubuntu/cloudfs/ghost_data/combined_high_inter_template_suspences/combined_high_inter_template_suspences_long_only_train_sample_1229_1672366480.csv     --valid_data  /home/ubuntu/cloudfs/ghost_data/combined_high_inter_template_suspences/combined_high_inter_template_suspences_long_only_val_sample_1229_1672366480.csv     --test_data  /home/ubuntu/cloudfs/ghost_data/combined_high_inter_template_suspences/combined_high_inter_template_suspences_long_only_val_sample_1229_1672366480.csv     --max_seq_length 500      '
+ CMD='     /home/ubuntu/cloudfs/Fengshenbang-LM/fengshen/examples/wenzhong_qa/finetune_bloomz_combined.py     
    --max_epochs 50     --accumulate_grad_batches 8     --gpus 4     --num_nodes 1     --strategy deepspeed_stage_2     --default_root_dir /home/ubuntu/cloudfs_nfs/saved_models/deep_speed_experiments/bloomz/combined_highinter_template_suspence_long_only     --dirpath /home/ubuntu/cloudfs_nfs/saved_models/deep_speed_experiments/bloomz/combined_highinter_template_suspence_long_only/ckpt_1672637296     --save_top_k 5     --monitor train_loss     --mode min     --save_last     --check_val_every_n_epoch 1      
    --pretrained_model_path /home/ubuntu/cloudfs/saved_models/bigscience/bloomz-3b     --enable_progress_bar True     --output_save_path /home/ubuntu/cloudfs_nfs/saved_models/deep_speed_experiments/bloomz/combined_highinter_template_suspence_long_only/predict.json     --learning_rate 1e-4     --weight_decay 0.1     --warmup 0.01     --run_ts 1672637296      
    --data_dir /home/ubuntu/cloudfs/ghost_data/merge_all_title_content/     --train_batchsize 1     --valid_batchsize 1     --train_data  /home/ubuntu/cloudfs/ghost_data/combined_high_inter_template_suspences/combined_high_inter_template_suspences_long_only_train_sample_1229_1672366480.csv     --valid_data  /home/ubuntu/cloudfs/ghost_data/combined_high_inter_template_suspences/combined_high_inter_template_suspences_long_only_val_sample_1229_1672366480.csv     --test_data  /home/ubuntu/cloudfs/ghost_data/combined_high_inter_template_suspences/combined_high_inter_template_suspences_long_only_val_sample_1229_1672366480.csv     --max_seq_length 500      '
+ echo /home/ubuntu/cloudfs/Fengshenbang-LM/fengshen/examples/wenzhong_qa/finetune_bloomz_combined.py --max_epochs 50 --accumulate_grad_batches 8 --gpus 4 --num_nodes 1 --strategy deepspeed_stage_2 --default_root_dir /home/ubuntu/cloudfs_nfs/saved_models/deep_speed_experiments/bloomz/combined_highinter_template_suspence_long_only --dirpath /home/ubuntu/cloudfs_nfs/saved_models/deep_speed_experiments/bloomz/combined_highinter_template_suspence_long_only/ckpt_1672637296 --save_top_k 5 --monitor train_loss --mode min --save_last --check_val_every_n_epoch 1 --pretrained_model_path /home/ubuntu/cloudfs/saved_models/bigscience/bloomz-3b --enable_progress_bar True --output_save_path /home/ubuntu/cloudfs_nfs/saved_models/deep_speed_experiments/bloomz/combined_highinter_template_suspence_long_only/predict.json --learning_rate 1e-4 --weight_decay 0.1 --warmup 0.01 --run_ts 1672637296 --data_dir /home/ubuntu/cloudfs/ghost_data/merge_all_title_content/ --train_batchsize 1 --valid_batchsize 1 --train_data /home/ubuntu/cloudfs/ghost_data/combined_high_inter_template_suspences/combined_high_inter_template_suspences_long_only_train_sample_1229_1672366480.csv --valid_data /home/ubuntu/cloudfs/ghost_data/combined_high_inter_template_suspences/combined_high_inter_template_suspences_long_only_val_sample_1229_1672366480.csv --test_data /home/ubuntu/cloudfs/ghost_data/combined_high_inter_template_suspences/combined_high_inter_template_suspences_long_only_val_sample_1229_1672366480.csv --max_seq_length 500
/home/ubuntu/cloudfs/Fengshenbang-LM/fengshen/examples/wenzhong_qa/finetune_bloomz_combined.py --max_epochs 50 --accumulate_grad_batches 8 --gpus 4 --num_nodes 1 --strategy deepspeed_stage_2 --default_root_dir /home/ubuntu/cloudfs_nfs/saved_models/deep_speed_experiments/bloomz/combined_highinter_template_suspence_long_only --dirpath /home/ubuntu/cloudfs_nfs/saved_models/deep_speed_experiments/bloomz/combined_highinter_template_suspence_long_only/ckpt_1672637296 --save_top_k 5 --monitor train_loss --mode min --save_last --check_val_every_n_epoch 1 --pretrained_model_path /home/ubuntu/cloudfs/saved_models/bigscience/bloomz-3b --enable_progress_bar True --output_save_path /home/ubuntu/cloudfs_nfs/saved_models/deep_speed_experiments/bloomz/combined_highinter_template_suspence_long_only/predict.json --learning_rate 1e-4 --weight_decay 0.1 --warmup 0.01 --run_ts 1672637296 --data_dir /home/ubuntu/cloudfs/ghost_data/merge_all_title_content/ --train_batchsize 1 --valid_batchsize 1 --train_data /home/ubuntu/cloudfs/ghost_data/combined_high_inter_template_suspences/combined_high_inter_template_suspences_long_only_train_sample_1229_1672366480.csv --valid_data /home/ubuntu/cloudfs/ghost_data/combined_high_inter_template_suspences/combined_high_inter_template_suspences_long_only_val_sample_1229_1672366480.csv --test_data /home/ubuntu/cloudfs/ghost_data/combined_high_inter_template_suspences/combined_high_inter_template_suspences_long_only_val_sample_1229_1672366480.csv --max_seq_length 500
+ python /home/ubuntu/cloudfs/Fengshenbang-LM/fengshen/examples/wenzhong_qa/finetune_bloomz_combined.py --max_epochs 50 --accumulate_grad_batches 8 --gpus 4 --num_nodes 1 --strategy deepspeed_stage_2 --default_root_dir /home/ubuntu/cloudfs_nfs/saved_models/deep_speed_experiments/bloomz/combined_highinter_template_suspence_long_only --dirpath /home/ubuntu/cloudfs_nfs/saved_models/deep_speed_experiments/bloomz/combined_highinter_template_suspence_long_only/ckpt_1672637296 --save_top_k 5 --monitor train_loss --mode min --save_last --check_val_every_n_epoch 1 --pretrained_model_path /home/ubuntu/cloudfs/saved_models/bigscience/bloomz-3b --enable_progress_bar True --output_save_path /home/ubuntu/cloudfs_nfs/saved_models/deep_speed_experiments/bloomz/combined_highinter_template_suspence_long_only/predict.json --learning_rate 1e-4 --weight_decay 0.1 --warmup 0.01 --run_ts 1672637296 --data_dir /home/ubuntu/cloudfs/ghost_data/merge_all_title_content/ --train_batchsize 1 --valid_batchsize 1 --train_data /home/ubuntu/cloudfs/ghost_data/combined_high_inter_template_suspences/combined_high_inter_template_suspences_long_only_train_sample_1229_1672366480.csv --valid_data /home/ubuntu/cloudfs/ghost_data/combined_high_inter_template_suspences/combined_high_inter_template_suspences_long_only_val_sample_1229_1672366480.csv --test_data /home/ubuntu/cloudfs/ghost_data/combined_high_inter_template_suspences/combined_high_inter_template_suspences_long_only_val_sample_1229_1672366480.csv --max_seq_length 500
['/home/ubuntu/cloudfs/Fengshenbang-LM/fengshen/examples/wenzhong_qa', '/home/ubuntu/miniconda3/envs/ghostaienv/lib/python38.zip', '/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8', '/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/lib-dynload', '/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages', '../..']
args:Namespace(accelerator=None, accumulate_grad_batches=8, amp_backend='native', amp_level=None, auto_lr_find=False, auto_scale_batch_size=False, auto_select_gpus=False, benchmark=None, check_val_every_n_epoch=1, data_dir='/home/ubuntu/cloudfs/ghost_data/merge_all_title_content/', default_root_dir='/home/ubuntu/cloudfs_nfs/saved_models/deep_speed_experiments/bloomz/combined_highinter_template_suspence_long_only', detect_anomaly=False, deterministic=None, devices=None, dirpath='/home/ubuntu/cloudfs_nfs/saved_models/deep_speed_experiments/bloomz/combined_highinter_template_suspence_long_only/ckpt_1672637296', do_eval_only=False, enable_checkpointing=True, enable_model_summary=True, enable_progress_bar=True, every_n_train_steps=1000, fast_dev_run=False, filename='model-{epoch:02d}-{train_loss:.4f}', gpus=4, gradient_clip_algorithm=None, gradient_clip_val=None, ipus=None, learning_rate=0.0001, limit_predict_batches=None, limit_test_batches=None, limit_train_batches=None, limit_val_batches=None, log_every_n_steps=50, logger=True, max_epochs=50, max_seq_length=500, max_steps=-1, max_time=None, min_epochs=None, min_steps=None, mode='min', monitor='train_loss', move_metrics_to_cpu=False, multiple_trainloader_mode='max_size_cycle', num_nodes=1, num_processes=None, num_sanity_val_steps=2, num_workers=2, output_save_path='/home/ubuntu/cloudfs_nfs/saved_models/deep_speed_experiments/bloomz/combined_highinter_template_suspence_long_only/predict.json', overfit_batches=0.0, plugins=None, precision=32, pretrained_model_path='/home/ubuntu/cloudfs/saved_models/bigscience/bloomz-3b', profiler=None, reload_dataloaders_every_n_epochs=0, replace_sampler_ddp=True, resume_from_checkpoint=None, run_ts='1672637296', save_last=True, save_top_k=5.0, save_weights_only=True, strategy='deepspeed_stage_2', sync_batchnorm=False, test_data='/home/ubuntu/cloudfs/ghost_data/combined_high_inter_template_suspences/combined_high_inter_template_suspences_long_only_val_sample_1229_1672366480.csv', test_only=False, tpu_cores=None, track_grad_norm=-1, train_batchsize=1, train_data='/home/ubuntu/cloudfs/ghost_data/combined_high_inter_template_suspences/combined_high_inter_template_suspences_long_only_train_sample_1229_1672366480.csv', val_check_interval=None, valid_batchsize=1, valid_data='/home/ubuntu/cloudfs/ghost_data/combined_high_inter_template_suspences/combined_high_inter_template_suspences_long_only_val_sample_1229_1672366480.csv', warmup=0.01, weight_decay=0.1, weights_save_path=None)
num_data: 1000
/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:447: LightningDeprecationWarning: Setting `Trainer(gpus=4)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=4)` instead.
  rank_zero_deprecation(
Loading DeepSpeed config from set PL_DEEPSPEED_CONFIG_PATH environment variable
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
initializing deepspeed distributed: GLOBAL_RANK: 0, MEMBER: 1/4
['/home/ubuntu/cloudfs/Fengshenbang-LM/fengshen/examples/wenzhong_qa', '/home/ubuntu/miniconda3/envs/ghostaienv/lib/python38.zip', '/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8', '/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/lib-dynload', '/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages', '../..']
args:Namespace(accelerator=None, accumulate_grad_batches=8, amp_backend='native', amp_level=None, auto_lr_find=False, auto_scale_batch_size=False, auto_select_gpus=False, benchmark=None, check_val_every_n_epoch=1, data_dir='/home/ubuntu/cloudfs/ghost_data/merge_all_title_content/', default_root_dir='/home/ubuntu/cloudfs_nfs/saved_models/deep_speed_experiments/bloomz/combined_highinter_template_suspence_long_only', detect_anomaly=False, deterministic=None, devices=None, dirpath='/home/ubuntu/cloudfs_nfs/saved_models/deep_speed_experiments/bloomz/combined_highinter_template_suspence_long_only/ckpt_1672637296', do_eval_only=False, enable_checkpointing=True, enable_model_summary=True, enable_progress_bar=True, every_n_train_steps=1000, fast_dev_run=False, filename='model-{epoch:02d}-{train_loss:.4f}', gpus=4, gradient_clip_algorithm=None, gradient_clip_val=None, ipus=None, learning_rate=0.0001, limit_predict_batches=None, limit_test_batches=None, limit_train_batches=None, limit_val_batches=None, log_every_n_steps=50, logger=True, max_epochs=50, max_seq_length=500, max_steps=-1, max_time=None, min_epochs=None, min_steps=None, mode='min', monitor='train_loss', move_metrics_to_cpu=False, multiple_trainloader_mode='max_size_cycle', num_nodes=1, num_processes=None, num_sanity_val_steps=2, num_workers=2, output_save_path='/home/ubuntu/cloudfs_nfs/saved_models/deep_speed_experiments/bloomz/combined_highinter_template_suspence_long_only/predict.json', overfit_batches=0.0, plugins=None, precision=32, pretrained_model_path='/home/ubuntu/cloudfs/saved_models/bigscience/bloomz-3b', profiler=None, reload_dataloaders_every_n_epochs=0, replace_sampler_ddp=True, resume_from_checkpoint=None, run_ts='1672637296', save_last=True, save_top_k=5.0, save_weights_only=True, strategy='deepspeed_stage_2', sync_batchnorm=False, test_data='/home/ubuntu/cloudfs/ghost_data/combined_high_inter_template_suspences/combined_high_inter_template_suspences_long_only_val_sample_1229_1672366480.csv', test_only=False, tpu_cores=None, track_grad_norm=-1, train_batchsize=1, train_data='/home/ubuntu/cloudfs/ghost_data/combined_high_inter_template_suspences/combined_high_inter_template_suspences_long_only_train_sample_1229_1672366480.csv', val_check_interval=None, valid_batchsize=1, valid_data='/home/ubuntu/cloudfs/ghost_data/combined_high_inter_template_suspences/combined_high_inter_template_suspences_long_only_val_sample_1229_1672366480.csv', warmup=0.01, weight_decay=0.1, weights_save_path=None)
num_data: 1000
initializing deepspeed distributed: GLOBAL_RANK: 1, MEMBER: 2/4
['/home/ubuntu/cloudfs/Fengshenbang-LM/fengshen/examples/wenzhong_qa', '/home/ubuntu/miniconda3/envs/ghostaienv/lib/python38.zip', '/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8', '/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/lib-dynload', '/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages', '../..']
args:Namespace(accelerator=None, accumulate_grad_batches=8, amp_backend='native', amp_level=None, auto_lr_find=False, auto_scale_batch_size=False, auto_select_gpus=False, benchmark=None, check_val_every_n_epoch=1, data_dir='/home/ubuntu/cloudfs/ghost_data/merge_all_title_content/', default_root_dir='/home/ubuntu/cloudfs_nfs/saved_models/deep_speed_experiments/bloomz/combined_highinter_template_suspence_long_only', detect_anomaly=False, deterministic=None, devices=None, dirpath='/home/ubuntu/cloudfs_nfs/saved_models/deep_speed_experiments/bloomz/combined_highinter_template_suspence_long_only/ckpt_1672637296', do_eval_only=False, enable_checkpointing=True, enable_model_summary=True, enable_progress_bar=True, every_n_train_steps=1000, fast_dev_run=False, filename='model-{epoch:02d}-{train_loss:.4f}', gpus=4, gradient_clip_algorithm=None, gradient_clip_val=None, ipus=None, learning_rate=0.0001, limit_predict_batches=None, limit_test_batches=None, limit_train_batches=None, limit_val_batches=None, log_every_n_steps=50, logger=True, max_epochs=50, max_seq_length=500, max_steps=-1, max_time=None, min_epochs=None, min_steps=None, mode='min', monitor='train_loss', move_metrics_to_cpu=False, multiple_trainloader_mode='max_size_cycle', num_nodes=1, num_processes=None, num_sanity_val_steps=2, num_workers=2, output_save_path='/home/ubuntu/cloudfs_nfs/saved_models/deep_speed_experiments/bloomz/combined_highinter_template_suspence_long_only/predict.json', overfit_batches=0.0, plugins=None, precision=32, pretrained_model_path='/home/ubuntu/cloudfs/saved_models/bigscience/bloomz-3b', profiler=None, reload_dataloaders_every_n_epochs=0, replace_sampler_ddp=True, resume_from_checkpoint=None, run_ts='1672637296', save_last=True, save_top_k=5.0, save_weights_only=True, strategy='deepspeed_stage_2', sync_batchnorm=False, test_data='/home/ubuntu/cloudfs/ghost_data/combined_high_inter_template_suspences/combined_high_inter_template_suspences_long_only_val_sample_1229_1672366480.csv', test_only=False, tpu_cores=None, track_grad_norm=-1, train_batchsize=1, train_data='/home/ubuntu/cloudfs/ghost_data/combined_high_inter_template_suspences/combined_high_inter_template_suspences_long_only_train_sample_1229_1672366480.csv', val_check_interval=None, valid_batchsize=1, valid_data='/home/ubuntu/cloudfs/ghost_data/combined_high_inter_template_suspences/combined_high_inter_template_suspences_long_only_val_sample_1229_1672366480.csv', warmup=0.01, weight_decay=0.1, weights_save_path=None)
num_data: 1000
['/home/ubuntu/cloudfs/Fengshenbang-LM/fengshen/examples/wenzhong_qa', '/home/ubuntu/miniconda3/envs/ghostaienv/lib/python38.zip', '/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8', '/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/lib-dynload', '/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages', '../..']
args:Namespace(accelerator=None, accumulate_grad_batches=8, amp_backend='native', amp_level=None, auto_lr_find=False, auto_scale_batch_size=False, auto_select_gpus=False, benchmark=None, check_val_every_n_epoch=1, data_dir='/home/ubuntu/cloudfs/ghost_data/merge_all_title_content/', default_root_dir='/home/ubuntu/cloudfs_nfs/saved_models/deep_speed_experiments/bloomz/combined_highinter_template_suspence_long_only', detect_anomaly=False, deterministic=None, devices=None, dirpath='/home/ubuntu/cloudfs_nfs/saved_models/deep_speed_experiments/bloomz/combined_highinter_template_suspence_long_only/ckpt_1672637296', do_eval_only=False, enable_checkpointing=True, enable_model_summary=True, enable_progress_bar=True, every_n_train_steps=1000, fast_dev_run=False, filename='model-{epoch:02d}-{train_loss:.4f}', gpus=4, gradient_clip_algorithm=None, gradient_clip_val=None, ipus=None, learning_rate=0.0001, limit_predict_batches=None, limit_test_batches=None, limit_train_batches=None, limit_val_batches=None, log_every_n_steps=50, logger=True, max_epochs=50, max_seq_length=500, max_steps=-1, max_time=None, min_epochs=None, min_steps=None, mode='min', monitor='train_loss', move_metrics_to_cpu=False, multiple_trainloader_mode='max_size_cycle', num_nodes=1, num_processes=None, num_sanity_val_steps=2, num_workers=2, output_save_path='/home/ubuntu/cloudfs_nfs/saved_models/deep_speed_experiments/bloomz/combined_highinter_template_suspence_long_only/predict.json', overfit_batches=0.0, plugins=None, precision=32, pretrained_model_path='/home/ubuntu/cloudfs/saved_models/bigscience/bloomz-3b', profiler=None, reload_dataloaders_every_n_epochs=0, replace_sampler_ddp=True, resume_from_checkpoint=None, run_ts='1672637296', save_last=True, save_top_k=5.0, save_weights_only=True, strategy='deepspeed_stage_2', sync_batchnorm=False, test_data='/home/ubuntu/cloudfs/ghost_data/combined_high_inter_template_suspences/combined_high_inter_template_suspences_long_only_val_sample_1229_1672366480.csv', test_only=False, tpu_cores=None, track_grad_norm=-1, train_batchsize=1, train_data='/home/ubuntu/cloudfs/ghost_data/combined_high_inter_template_suspences/combined_high_inter_template_suspences_long_only_train_sample_1229_1672366480.csv', val_check_interval=None, valid_batchsize=1, valid_data='/home/ubuntu/cloudfs/ghost_data/combined_high_inter_template_suspences/combined_high_inter_template_suspences_long_only_val_sample_1229_1672366480.csv', warmup=0.01, weight_decay=0.1, weights_save_path=None)
num_data: 1000
initializing deepspeed distributed: GLOBAL_RANK: 2, MEMBER: 3/4
initializing deepspeed distributed: GLOBAL_RANK: 3, MEMBER: 4/4
Total training step: 1562
Total training step: 1562
Total training step: 1562
Total training step: 1562
/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:2182: LightningDeprecationWarning: `Trainer.gpus` was deprecated in v1.6 and will be removed in v1.8. Please use `Trainer.num_devices` or `Trainer.device_ids` to get device information instead.
  rank_zero_deprecation(
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
You have specified an optimizer and/or scheduler within the DeepSpeed config. It is recommended to define it in `LightningModule.configure_optimizers`.
LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]

  | Name  | Type             | Params
-------------------------------------------
0 | model | BloomForCausalLM | 3.0 B 
-------------------------------------------
3.0 B     Trainable params
0         Non-trainable params
3.0 B     Total params
12,010.230Total estimated model params size (MB)
Missing logger folder: /home/ubuntu/cloudfs_nfs/saved_models/deep_speed_experiments/bloomz/combined_highinter_template_suspence_long_only/log/bloomz_combined
Rank: 0 partition count [4] and sizes[(750639360, False)] 
Sanity Checking: 0it [00:00, ?it/s]/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:236: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 82 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Rank: 2 partition count [4] and sizes[(750639360, False)] 
Rank: 1 partition count [4] and sizes[(750639360, False)] 
Rank: 3 partition count [4] and sizes[(750639360, False)] 
Sanity Checking:   0%|          | 0/2 [00:00<?, ?it/s]Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]Sanity Checking DataLoader 0:  50%|█████     | 1/2 [00:01<00:01,  1.06s/it]Sanity Checking DataLoader 0: 100%|██████████| 2/2 [00:01<00:00,  1.81it/s]
validation_epoch_end...
--0/4--- input text: 根据指定内容，撰写爆款小红书笔记标题。
需要起标题的内容：[暗黑系美甲]
最适合的标题类型：构造悬念。
小红书标题：[
validation_samples:
predictions: [(-0.1439512073993683, '根据指定内容，撰写爆款小红书笔记标题。\n需要起标题的内容：[暗黑系美甲]\n最适合的标题类型：构造悬念。\n小红书标题：[暗夜下的美甲]\n\n[暗黑美甲]')]
--1/4--- input text: 根据指定内容，撰写爆款小红书笔记标题。
需要起标题的内容：[扫地机器人]
最适合的标题类型：构造悬念。
小红书标题：[
validation_samples:
predictions: [(-0.11482423543930054, '根据指定内容，撰写爆款小红书笔记标题。\n需要起标题的内容：[扫地机器人]\n最适合的标题类型：构造悬念。\n小红书标题：[推荐] 扫地机器人哪个牌子好？')]
--2/4--- input text: 根据指定内容，撰写爆款小红书笔记标题。
需要起标题的内容：[草原羊肉]
最适合的标题类型：构造悬念。
小红书标题：[
validation_samples:
predictions: [(-0.16553734242916107, '根据指定内容，撰写爆款小红书笔记标题。\n需要起标题的内容：[草原羊肉]\n最适合的标题类型：构造悬念。\n小红书标题：[草原羊]')]
--3/4--- input text: 根据指定内容，撰写爆款小红书笔记标题。
需要起标题的内容：[真无线蓝牙耳机]
最适合的标题类型：构造悬念。
小红书标题：[
validation_samples:
predictions: [(-0.17649705708026886, '根据指定内容，撰写爆款小红书笔记标题。\n需要起标题的内容：[真无线蓝牙耳机]\n最适合的标题类型：构造悬念。\n小红书标题：[真無線蓝牙耳机]')]
                                                                           /home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:236: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 82 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Training: 0it [00:00, ?it/s]Training:   0%|          | 0/500 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/500 [00:00<?, ?it/s] 
validation_epoch_end...
--0/4--- input text: 根据指定内容，撰写爆款小红书笔记标题。
需要起标题的内容：[暗黑系美甲]
最适合的标题类型：构造悬念。
小红书标题：[
validation_samples:
predictions: [(-0.1357860565185547, '根据指定内容，撰写爆款小红书笔记标题。\n需要起标题的内容：[暗黑系美甲]\n最适合的标题类型：构造悬念。\n小红书标题：[暗夜美甲]\n\n[暗黑美甲]')]
--1/4--- input text: 根据指定内容，撰写爆款小红书笔记标题。
需要起标题的内容：[扫地机器人]
最适合的标题类型：构造悬念。
小红书标题：[
validation_samples:
predictions: [(-0.17607367038726807, '根据指定内容，撰写爆款小红书笔记标题。\n需要起标题的内容：[扫地机器人]\n最适合的标题类型：构造悬念。\n小红书标题：[扫 地 机器人] 扫地机器人哪个牌子好')]
--2/4--- input text: 根据指定内容，撰写爆款小红书笔记标题。
需要起标题的内容：[草原羊肉]
最适合的标题类型：构造悬念。
小红书标题：[
validation_samples:
predictions: [(-0.138450488448143, '根据指定内容，撰写爆款小红书笔记标题。\n需要起标题的内容：[草原羊肉]\n最适合的标题类型：构造悬念。\n小红书标题：[草原烤羊肉串]')]
--3/4--- input text: 根据指定内容，撰写爆款小红书笔记标题。
需要起标题的内容：[真无线蓝牙耳机]
最适合的标题类型：构造悬念。
小红书标题：[
validation_samples:
predictions: [(-0.17649705708026886, '根据指定内容，撰写爆款小红书笔记标题。\n需要起标题的内容：[真无线蓝牙耳机]\n最适合的标题类型：构造悬念。\n小红书标题：[真無線蓝牙耳机]')]

validation_epoch_end...
--0/4--- input text: 根据指定内容，撰写爆款小红书笔记标题。
需要起标题的内容：[暗黑系美甲]
最适合的标题类型：构造悬念。
小红书标题：[
validation_samples:
predictions: [(-0.1357860565185547, '根据指定内容，撰写爆款小红书笔记标题。\n需要起标题的内容：[暗黑系美甲]\n最适合的标题类型：构造悬念。\n小红书标题：[暗夜美甲]\n\n[暗黑美甲]')]
--1/4--- input text: 根据指定内容，撰写爆款小红书笔记标题。
需要起标题的内容：[扫地机器人]
最适合的标题类型：构造悬念。
小红书标题：[
validation_samples:
predictions: [(-0.18999707698822021, '根据指定内容，撰写爆款小红书笔记标题。\n需要起标题的内容：[扫地机器人]\n最适合的标题类型：构造悬念。\n小红书标题：[扫 地 机器人]哪个牌子好？')]
--2/4--- input text: 根据指定内容，撰写爆款小红书笔记标题。
需要起标题的内容：[草原羊肉]
最适合的标题类型：构造悬念。
小红书标题：[
validation_samples:
predictions: [(-0.13394881784915924, '根据指定内容，撰写爆款小红书笔记标题。\n需要起标题的内容：[草原羊肉]\n最适合的标题类型：构造悬念。\n小红书标题：[草原上的羊肉]')]
--3/4--- input text: 根据指定内容，撰写爆款小红书笔记标题。
需要起标题的内容：[真无线蓝牙耳机]
最适合的标题类型：构造悬念。
小红书标题：[
validation_samples:
predictions: [(-0.17082767188549042, '根据指定内容，撰写爆款小红书笔记标题。\n需要起标题的内容：[真无线蓝牙耳机]\n最适合的标题类型：构造悬念。\n小红书标题：[真無線蓝牙耳机]爆款笔记标题')]

validation_epoch_end...
--0/4--- input text: 根据指定内容，撰写爆款小红书笔记标题。
需要起标题的内容：[暗黑系美甲]
最适合的标题类型：构造悬念。
小红书标题：[
validation_samples:
predictions: [(-0.1473507583141327, '根据指定内容，撰写爆款小红书笔记标题。\n需要起标题的内容：[暗黑系美甲]\n最适合的标题类型：构造悬念。\n小红书标题：[暗夜美甲]')]
--1/4--- input text: 根据指定内容，撰写爆款小红书笔记标题。
需要起标题的内容：[扫地机器人]
最适合的标题类型：构造悬念。
小红书标题：[
validation_samples:
predictions: [(-0.16435222327709198, '根据指定内容，撰写爆款小红书笔记标题。\n需要起标题的内容：[扫地机器人]\n最适合的标题类型：构造悬念。\n小红书标题：[扫 地 机 器 官 网]')]
--2/4--- input text: 根据指定内容，撰写爆款小红书笔记标题。
需要起标题的内容：[草原羊肉]
最适合的标题类型：构造悬念。
小红书标题：[
validation_samples:
predictions: [(-0.15782307088375092, '根据指定内容，撰写爆款小红书笔记标题。\n需要起标题的内容：[草原羊肉]\n最适合的标题类型：构造悬念。\n小红书标题：[草原烤羊腿][草原羊肉][草原烤羊肉][草原羊肉]')]
--3/4--- input text: 根据指定内容，撰写爆款小红书笔记标题。
需要起标题的内容：[真无线蓝牙耳机]
最适合的标题类型：构造悬念。
小红书标题：[
validation_samples:
predictions: [(-0.15239939093589783, '根据指定内容，撰写爆款小红书笔记标题。\n需要起标题的内容：[真无线蓝牙耳机]\n最适合的标题类型：构造悬念。\n小红书标题：[耳机]真无线耳机哪个牌子好？')]
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
Epoch 0:   0%|          | 1/500 [00:00<03:50,  2.16it/s]Epoch 0:   0%|          | 1/500 [00:00<03:51,  2.16it/s, loss=0.554, v_num=0, train_loss_step=0.567]Epoch 0:   0%|          | 2/500 [00:00<02:26,  3.39it/s, loss=0.554, v_num=0, train_loss_step=0.567]Epoch 0:   0%|          | 2/500 [00:00<02:27,  3.38it/s, loss=0.415, v_num=0, train_loss_step=0.565]Epoch 0:   1%|          | 3/500 [00:00<02:07,  3.90it/s, loss=0.415, v_num=0, train_loss_step=0.565]Epoch 0:   1%|          | 3/500 [00:00<02:07,  3.89it/s, loss=0.351, v_num=0, train_loss_step=0.319]Epoch 0:   1%|          | 4/500 [00:00<01:59,  4.15it/s, loss=0.351, v_num=0, train_loss_step=0.319]Epoch 0:   1%|          | 4/500 [00:00<01:59,  4.15it/s, loss=0.45, v_num=0, train_loss_step=0.496] Epoch 0:   1%|          | 5/500 [00:01<01:50,  4.47it/s, loss=0.45, v_num=0, train_loss_step=0.496]Epoch 0:   1%|          | 5/500 [00:01<01:50,  4.47it/s, loss=0.455, v_num=0, train_loss_step=0.400]Epoch 0:   1%|          | 6/500 [00:01<01:43,  4.77it/s, loss=0.455, v_num=0, train_loss_step=0.400]Epoch 0:   1%|          | 6/500 [00:01<01:43,  4.77it/s, loss=0.553, v_num=0, train_loss_step=0.649]Epoch 0:   1%|▏         | 7/500 [00:01<01:40,  4.89it/s, loss=0.553, v_num=0, train_loss_step=0.649]Epoch 0:   1%|▏         | 7/500 [00:01<01:40,  4.89it/s, loss=0.505, v_num=0, train_loss_step=0.283]Epoch 0:   2%|▏         | 8/500 [00:01<01:39,  4.95it/s, loss=0.505, v_num=0, train_loss_step=0.283]Epoch 0:   2%|▏         | 8/500 [00:01<01:39,  4.95it/s, loss=0.502, v_num=0, train_loss_step=0.541]Epoch 0:   2%|▏         | 9/500 [00:01<01:36,  5.10it/s, loss=0.502, v_num=0, train_loss_step=0.541]Epoch 0:   2%|▏         | 9/500 [00:01<01:36,  5.10it/s, loss=0.49, v_num=0, train_loss_step=0.411] Epoch 0:   2%|▏         | 10/500 [00:01<01:33,  5.24it/s, loss=0.49, v_num=0, train_loss_step=0.411]Epoch 0:   2%|▏         | 10/500 [00:01<01:33,  5.24it/s, loss=0.464, v_num=0, train_loss_step=0.471]Epoch 0:   2%|▏         | 11/500 [00:02<01:31,  5.33it/s, loss=0.464, v_num=0, train_loss_step=0.471]Epoch 0:   2%|▏         | 11/500 [00:02<01:31,  5.33it/s, loss=0.439, v_num=0, train_loss_step=0.358]Epoch 0:   2%|▏         | 12/500 [00:02<01:30,  5.36it/s, loss=0.439, v_num=0, train_loss_step=0.358]Epoch 0:   2%|▏         | 12/500 [00:02<01:31,  5.36it/s, loss=0.417, v_num=0, train_loss_step=0.291]Epoch 0:   3%|▎         | 13/500 [00:02<01:29,  5.45it/s, loss=0.417, v_num=0, train_loss_step=0.291]Epoch 0:   3%|▎         | 13/500 [00:02<01:29,  5.45it/s, loss=0.416, v_num=0, train_loss_step=0.257]Epoch 0:   3%|▎         | 14/500 [00:02<01:28,  5.52it/s, loss=0.416, v_num=0, train_loss_step=0.257]Epoch 0:   3%|▎         | 14/500 [00:02<01:28,  5.52it/s, loss=0.412, v_num=0, train_loss_step=0.237]Epoch 0:   3%|▎         | 15/500 [00:02<01:26,  5.59it/s, loss=0.412, v_num=0, train_loss_step=0.237]Epoch 0:   3%|▎         | 15/500 [00:02<01:26,  5.59it/s, loss=0.399, v_num=0, train_loss_step=0.307]Epoch 0:   3%|▎         | 16/500 [00:02<01:26,  5.59it/s, loss=0.399, v_num=0, train_loss_step=0.307]Epoch 0:   3%|▎         | 16/500 [00:02<01:26,  5.59it/s, loss=0.402, v_num=0, train_loss_step=0.548]Epoch 0:   3%|▎         | 17/500 [00:02<01:24,  5.68it/s, loss=0.402, v_num=0, train_loss_step=0.548]Epoch 0:   3%|▎         | 17/500 [00:02<01:24,  5.68it/s, loss=0.409, v_num=0, train_loss_step=0.439]Epoch 0:   4%|▎         | 18/500 [00:03<01:24,  5.69it/s, loss=0.409, v_num=0, train_loss_step=0.439]Epoch 0:   4%|▎         | 18/500 [00:03<01:24,  5.69it/s, loss=0.398, v_num=0, train_loss_step=0.331]Epoch 0:   4%|▍         | 19/500 [00:03<01:23,  5.75it/s, loss=0.398, v_num=0, train_loss_step=0.331]Epoch 0:   4%|▍         | 19/500 [00:03<01:23,  5.75it/s, loss=0.387, v_num=0, train_loss_step=0.499]Epoch 0:   4%|▍         | 20/500 [00:03<01:22,  5.79it/s, loss=0.387, v_num=0, train_loss_step=0.499]Epoch 0:   4%|▍         | 20/500 [00:03<01:22,  5.79it/s, loss=0.383, v_num=0, train_loss_step=0.387]Epoch 0:   4%|▍         | 21/500 [00:03<01:22,  5.79it/s, loss=0.383, v_num=0, train_loss_step=0.387]Epoch 0:   4%|▍         | 21/500 [00:03<01:22,  5.79it/s, loss=0.399, v_num=0, train_loss_step=0.479]Epoch 0:   4%|▍         | 22/500 [00:03<01:22,  5.79it/s, loss=0.399, v_num=0, train_loss_step=0.479]Epoch 0:   4%|▍         | 22/500 [00:03<01:22,  5.79it/s, loss=0.405, v_num=0, train_loss_step=0.593]Epoch 0:   5%|▍         | 23/500 [00:03<01:21,  5.87it/s, loss=0.405, v_num=0, train_loss_step=0.593]Epoch 0:   5%|▍         | 23/500 [00:03<01:21,  5.87it/s, loss=0.415, v_num=0, train_loss_step=0.527]Epoch 0:   5%|▍         | 24/500 [00:04<01:20,  5.91it/s, loss=0.415, v_num=0, train_loss_step=0.527]Epoch 0:   5%|▍         | 24/500 [00:04<01:20,  5.91it/s, loss=0.402, v_num=0, train_loss_step=0.366]Epoch 0:   5%|▌         | 25/500 [00:04<01:19,  5.96it/s, loss=0.402, v_num=0, train_loss_step=0.366]Epoch 0:   5%|▌         | 25/500 [00:04<01:19,  5.96it/s, loss=0.405, v_num=0, train_loss_step=0.386]Epoch 0:   5%|▌         | 26/500 [00:04<01:18,  6.01it/s, loss=0.405, v_num=0, train_loss_step=0.386]Epoch 0:   5%|▌         | 26/500 [00:04<01:18,  6.01it/s, loss=0.387, v_num=0, train_loss_step=0.527]Epoch 0:   5%|▌         | 27/500 [00:04<01:17,  6.07it/s, loss=0.387, v_num=0, train_loss_step=0.527]Epoch 0:   5%|▌         | 27/500 [00:04<01:17,  6.07it/s, loss=0.396, v_num=0, train_loss_step=0.450]Epoch 0:   6%|▌         | 28/500 [00:04<01:17,  6.08it/s, loss=0.396, v_num=0, train_loss_step=0.450]Epoch 0:   6%|▌         | 28/500 [00:04<01:17,  6.08it/s, loss=0.417, v_num=0, train_loss_step=0.445]Epoch 0:   6%|▌         | 29/500 [00:04<01:17,  6.07it/s, loss=0.417, v_num=0, train_loss_step=0.445]Epoch 0:   6%|▌         | 29/500 [00:04<01:17,  6.07it/s, loss=0.419, v_num=0, train_loss_step=0.557]Epoch 0:   6%|▌         | 30/500 [00:04<01:17,  6.06it/s, loss=0.419, v_num=0, train_loss_step=0.557]Epoch 0:   6%|▌         | 30/500 [00:04<01:17,  6.06it/s, loss=0.425, v_num=0, train_loss_step=0.276]Epoch 0:   6%|▌         | 31/500 [00:05<01:17,  6.05it/s, loss=0.425, v_num=0, train_loss_step=0.276]Epoch 0:   6%|▌         | 31/500 [00:05<01:17,  6.05it/s, loss=0.427, v_num=0, train_loss_step=0.309]Epoch 0:   6%|▋         | 32/500 [00:05<01:17,  6.03it/s, loss=0.427, v_num=0, train_loss_step=0.309]Epoch 0:   6%|▋         | 32/500 [00:05<01:17,  6.03it/s, loss=0.466, v_num=0, train_loss_step=0.532]Epoch 0:   7%|▋         | 33/500 [00:05<01:16,  6.09it/s, loss=0.466, v_num=0, train_loss_step=0.532]Epoch 0:   7%|▋         | 33/500 [00:05<01:16,  6.09it/s, loss=0.476, v_num=0, train_loss_step=0.651]Epoch 0:   7%|▋         | 34/500 [00:05<01:16,  6.08it/s, loss=0.476, v_num=0, train_loss_step=0.651]Epoch 0:   7%|▋         | 34/500 [00:05<01:16,  6.08it/s, loss=0.479, v_num=0, train_loss_step=0.347]Epoch 0:   7%|▋         | 35/500 [00:05<01:16,  6.11it/s, loss=0.479, v_num=0, train_loss_step=0.347]Epoch 0:   7%|▋         | 35/500 [00:05<01:16,  6.11it/s, loss=0.489, v_num=0, train_loss_step=0.588]Epoch 0:   7%|▋         | 36/500 [00:05<01:16,  6.10it/s, loss=0.489, v_num=0, train_loss_step=0.588]Epoch 0:   7%|▋         | 36/500 [00:05<01:16,  6.10it/s, loss=0.508, v_num=0, train_loss_step=0.300]Epoch 0:   7%|▋         | 37/500 [00:06<01:16,  6.09it/s, loss=0.508, v_num=0, train_loss_step=0.300]Epoch 0:   7%|▋         | 37/500 [00:06<01:16,  6.09it/s, loss=0.52, v_num=0, train_loss_step=0.561] Epoch 0:   8%|▊         | 38/500 [00:06<01:16,  6.08it/s, loss=0.52, v_num=0, train_loss_step=0.561]Epoch 0:   8%|▊         | 38/500 [00:06<01:16,  6.08it/s, loss=0.556, v_num=0, train_loss_step=0.488]Epoch 0:   8%|▊         | 39/500 [00:06<01:15,  6.07it/s, loss=0.556, v_num=0, train_loss_step=0.488]Epoch 0:   8%|▊         | 39/500 [00:06<01:16,  6.07it/s, loss=0.567, v_num=0, train_loss_step=0.372]Epoch 0:   8%|▊         | 40/500 [00:06<01:16,  6.04it/s, loss=0.567, v_num=0, train_loss_step=0.372]Epoch 0:   8%|▊         | 40/500 [00:06<01:16,  6.04it/s, loss=0.56, v_num=0, train_loss_step=0.236] Epoch 0:   8%|▊         | 41/500 [00:06<01:16,  6.04it/s, loss=0.56, v_num=0, train_loss_step=0.236]Epoch 0:   8%|▊         | 41/500 [00:06<01:16,  6.04it/s, loss=0.525, v_num=0, train_loss_step=0.271]Epoch 0:   8%|▊         | 42/500 [00:06<01:15,  6.05it/s, loss=0.525, v_num=0, train_loss_step=0.271]Epoch 0:   8%|▊         | 42/500 [00:06<01:15,  6.05it/s, loss=0.512, v_num=0, train_loss_step=0.204]Epoch 0:   9%|▊         | 43/500 [00:07<01:15,  6.04it/s, loss=0.512, v_num=0, train_loss_step=0.204]Epoch 0:   9%|▊         | 43/500 [00:07<01:15,  6.04it/s, loss=0.545, v_num=0, train_loss_step=0.515]Epoch 0:   9%|▉         | 44/500 [00:07<01:15,  6.03it/s, loss=0.545, v_num=0, train_loss_step=0.515]Epoch 0:   9%|▉         | 44/500 [00:07<01:15,  6.03it/s, loss=0.528, v_num=0, train_loss_step=0.265]Epoch 0:   9%|▉         | 45/500 [00:07<01:15,  6.02it/s, loss=0.528, v_num=0, train_loss_step=0.265]Epoch 0:   9%|▉         | 45/500 [00:07<01:15,  6.02it/s, loss=0.525, v_num=0, train_loss_step=0.331]Epoch 0:   9%|▉         | 46/500 [00:07<01:15,  6.02it/s, loss=0.525, v_num=0, train_loss_step=0.331]Epoch 0:   9%|▉         | 46/500 [00:07<01:15,  6.02it/s, loss=0.513, v_num=0, train_loss_step=0.400]Epoch 0:   9%|▉         | 47/500 [00:07<01:15,  6.01it/s, loss=0.513, v_num=0, train_loss_step=0.400]Epoch 0:   9%|▉         | 47/500 [00:07<01:15,  6.01it/s, loss=0.502, v_num=0, train_loss_step=0.226]Epoch 0:  10%|▉         | 48/500 [00:07<01:15,  6.01it/s, loss=0.502, v_num=0, train_loss_step=0.226]Epoch 0:  10%|▉         | 48/500 [00:07<01:15,  6.01it/s, loss=0.48, v_num=0, train_loss_step=0.381] Epoch 0:  10%|▉         | 49/500 [00:08<01:15,  6.01it/s, loss=0.48, v_num=0, train_loss_step=0.381]Epoch 0:  10%|▉         | 49/500 [00:08<01:15,  6.00it/s, loss=0.51, v_num=0, train_loss_step=0.467]Epoch 0:  10%|█         | 50/500 [00:08<01:15,  6.00it/s, loss=0.51, v_num=0, train_loss_step=0.467]Epoch 0:  10%|█         | 50/500 [00:08<01:15,  6.00it/s, loss=0.5, v_num=0, train_loss_step=0.240] Epoch 0:  10%|█         | 51/500 [00:08<01:14,  6.02it/s, loss=0.5, v_num=0, train_loss_step=0.240]Epoch 0:  10%|█         | 51/500 [00:08<01:14,  6.02it/s, loss=0.504, v_num=0, train_loss_step=0.364]Epoch 0:  10%|█         | 52/500 [00:08<01:14,  6.05it/s, loss=0.504, v_num=0, train_loss_step=0.364]Epoch 0:  10%|█         | 52/500 [00:08<01:14,  6.05it/s, loss=0.474, v_num=0, train_loss_step=0.449]Epoch 0:  11%|█         | 53/500 [00:08<01:13,  6.07it/s, loss=0.474, v_num=0, train_loss_step=0.449]Epoch 0:  11%|█         | 53/500 [00:08<01:13,  6.07it/s, loss=0.458, v_num=0, train_loss_step=0.435]Epoch 0:  11%|█         | 54/500 [00:08<01:13,  6.07it/s, loss=0.458, v_num=0, train_loss_step=0.435]Epoch 0:  11%|█         | 54/500 [00:08<01:13,  6.07it/s, loss=0.449, v_num=0, train_loss_step=0.278]Epoch 0:  11%|█         | 55/500 [00:09<01:13,  6.07it/s, loss=0.449, v_num=0, train_loss_step=0.278]Epoch 0:  11%|█         | 55/500 [00:09<01:13,  6.07it/s, loss=0.441, v_num=0, train_loss_step=0.492]Epoch 0:  11%|█         | 56/500 [00:09<01:13,  6.06it/s, loss=0.441, v_num=0, train_loss_step=0.492]Epoch 0:  11%|█         | 56/500 [00:09<01:13,  6.06it/s, loss=0.416, v_num=0, train_loss_step=0.253]Epoch 0:  11%|█▏        | 57/500 [00:09<01:12,  6.08it/s, loss=0.416, v_num=0, train_loss_step=0.253]Epoch 0:  11%|█▏        | 57/500 [00:09<01:12,  6.08it/s, loss=0.39, v_num=0, train_loss_step=0.458] Epoch 0:  12%|█▏        | 58/500 [00:09<01:12,  6.07it/s, loss=0.39, v_num=0, train_loss_step=0.458]Epoch 0:  12%|█▏        | 58/500 [00:09<01:12,  6.07it/s, loss=0.364, v_num=0, train_loss_step=0.348]Epoch 0:  12%|█▏        | 59/500 [00:09<01:12,  6.08it/s, loss=0.364, v_num=0, train_loss_step=0.348]Epoch 0:  12%|█▏        | 59/500 [00:09<01:12,  6.08it/s, loss=0.38, v_num=0, train_loss_step=0.400] Epoch 0:  12%|█▏        | 60/500 [00:09<01:12,  6.08it/s, loss=0.38, v_num=0, train_loss_step=0.400]Epoch 0:  12%|█▏        | 60/500 [00:09<01:12,  6.08it/s, loss=0.4, v_num=0, train_loss_step=0.411] Epoch 0:  12%|█▏        | 61/500 [00:10<01:12,  6.07it/s, loss=0.4, v_num=0, train_loss_step=0.411]Epoch 0:  12%|█▏        | 61/500 [00:10<01:12,  6.07it/s, loss=0.41, v_num=0, train_loss_step=0.367]Epoch 0:  12%|█▏        | 62/500 [00:10<01:12,  6.07it/s, loss=0.41, v_num=0, train_loss_step=0.367]Epoch 0:  12%|█▏        | 62/500 [00:10<01:12,  6.07it/s, loss=0.425, v_num=0, train_loss_step=0.512]Epoch 0:  13%|█▎        | 63/500 [00:10<01:12,  6.06it/s, loss=0.425, v_num=0, train_loss_step=0.512]Epoch 0:  13%|█▎        | 63/500 [00:10<01:12,  6.06it/s, loss=0.382, v_num=0, train_loss_step=0.355]Epoch 0:  13%|█▎        | 64/500 [00:10<01:11,  6.06it/s, loss=0.382, v_num=0, train_loss_step=0.355]Epoch 0:  13%|█▎        | 64/500 [00:10<01:11,  6.06it/s, loss=0.385, v_num=0, train_loss_step=0.299]Epoch 0:  13%|█▎        | 65/500 [00:10<01:11,  6.09it/s, loss=0.385, v_num=0, train_loss_step=0.299]Epoch 0:  13%|█▎        | 65/500 [00:10<01:11,  6.08it/s, loss=0.375, v_num=0, train_loss_step=0.421]Epoch 0:  13%|█▎        | 66/500 [00:10<01:11,  6.08it/s, loss=0.375, v_num=0, train_loss_step=0.421]Epoch 0:  13%|█▎        | 66/500 [00:10<01:11,  6.08it/s, loss=0.392, v_num=0, train_loss_step=0.436]Epoch 0:  13%|█▎        | 67/500 [00:10<01:10,  6.11it/s, loss=0.392, v_num=0, train_loss_step=0.436]Epoch 0:  13%|█▎        | 67/500 [00:10<01:10,  6.11it/s, loss=0.421, v_num=0, train_loss_step=0.535]Epoch 0:  14%|█▎        | 68/500 [00:11<01:10,  6.10it/s, loss=0.421, v_num=0, train_loss_step=0.535]Epoch 0:  14%|█▎        | 68/500 [00:11<01:10,  6.10it/s, loss=0.429, v_num=0, train_loss_step=0.410]Epoch 0:  14%|█▍        | 69/500 [00:11<01:10,  6.12it/s, loss=0.429, v_num=0, train_loss_step=0.410]Epoch 0:  14%|█▍        | 69/500 [00:11<01:10,  6.12it/s, loss=0.415, v_num=0, train_loss_step=0.678]Epoch 0:  14%|█▍        | 70/500 [00:11<01:10,  6.11it/s, loss=0.415, v_num=0, train_loss_step=0.678]Epoch 0:  14%|█▍        | 70/500 [00:11<01:10,  6.11it/s, loss=0.424, v_num=0, train_loss_step=0.227]Epoch 0:  14%|█▍        | 71/500 [00:11<01:10,  6.10it/s, loss=0.424, v_num=0, train_loss_step=0.227]Epoch 0:  14%|█▍        | 71/500 [00:11<01:10,  6.10it/s, loss=0.429, v_num=0, train_loss_step=0.249]Epoch 0:  14%|█▍        | 72/500 [00:11<01:10,  6.09it/s, loss=0.429, v_num=0, train_loss_step=0.249]Epoch 0:  14%|█▍        | 72/500 [00:11<01:10,  6.09it/s, loss=0.418, v_num=0, train_loss_step=0.356]Epoch 0:  15%|█▍        | 73/500 [00:11<01:10,  6.09it/s, loss=0.418, v_num=0, train_loss_step=0.356]Epoch 0:  15%|█▍        | 73/500 [00:11<01:10,  6.09it/s, loss=0.429, v_num=0, train_loss_step=0.254]Epoch 0:  15%|█▍        | 74/500 [00:12<01:09,  6.09it/s, loss=0.429, v_num=0, train_loss_step=0.254]Epoch 0:  15%|█▍        | 74/500 [00:12<01:10,  6.09it/s, loss=0.436, v_num=0, train_loss_step=0.613]Epoch 0:  15%|█▌        | 75/500 [00:12<01:09,  6.08it/s, loss=0.436, v_num=0, train_loss_step=0.613]Epoch 0:  15%|█▌        | 75/500 [00:12<01:09,  6.08it/s, loss=0.448, v_num=0, train_loss_step=0.500]Epoch 0:  15%|█▌        | 76/500 [00:12<01:09,  6.09it/s, loss=0.448, v_num=0, train_loss_step=0.500]Epoch 0:  15%|█▌        | 76/500 [00:12<01:09,  6.09it/s, loss=0.451, v_num=0, train_loss_step=0.267]Epoch 0:  15%|█▌        | 77/500 [00:12<01:09,  6.10it/s, loss=0.451, v_num=0, train_loss_step=0.267]Epoch 0:  15%|█▌        | 77/500 [00:12<01:09,  6.10it/s, loss=0.461, v_num=0, train_loss_step=0.387]Epoch 0:  16%|█▌        | 78/500 [00:12<01:09,  6.10it/s, loss=0.461, v_num=0, train_loss_step=0.387]Epoch 0:  16%|█▌        | 78/500 [00:12<01:09,  6.10it/s, loss=0.464, v_num=0, train_loss_step=0.686]Epoch 0:  16%|█▌        | 79/500 [00:12<01:09,  6.09it/s, loss=0.464, v_num=0, train_loss_step=0.686]Epoch 0:  16%|█▌        | 79/500 [00:12<01:09,  6.09it/s, loss=0.455, v_num=0, train_loss_step=0.393]Epoch 0:  16%|█▌        | 80/500 [00:13<01:09,  6.09it/s, loss=0.455, v_num=0, train_loss_step=0.393]Epoch 0:  16%|█▌        | 80/500 [00:13<01:09,  6.09it/s, loss=0.447, v_num=0, train_loss_step=0.386]Epoch 0:  16%|█▌        | 81/500 [00:13<01:08,  6.09it/s, loss=0.447, v_num=0, train_loss_step=0.386]Epoch 0:  16%|█▌        | 81/500 [00:13<01:08,  6.09it/s, loss=0.435, v_num=0, train_loss_step=0.281]Epoch 0:  16%|█▋        | 82/500 [00:13<01:08,  6.09it/s, loss=0.435, v_num=0, train_loss_step=0.281]Epoch 0:  16%|█▋        | 82/500 [00:13<01:08,  6.09it/s, loss=0.442, v_num=0, train_loss_step=0.393]Epoch 0:  17%|█▋        | 83/500 [00:13<01:08,  6.09it/s, loss=0.442, v_num=0, train_loss_step=0.393]Epoch 0:  17%|█▋        | 83/500 [00:13<01:08,  6.09it/s, loss=0.454, v_num=0, train_loss_step=0.327]Epoch 0:  17%|█▋        | 84/500 [00:13<01:08,  6.09it/s, loss=0.454, v_num=0, train_loss_step=0.327]Epoch 0:  17%|█▋        | 84/500 [00:13<01:08,  6.08it/s, loss=0.453, v_num=0, train_loss_step=0.314]Epoch 0:  17%|█▋        | 85/500 [00:13<01:08,  6.08it/s, loss=0.453, v_num=0, train_loss_step=0.314]Epoch 0:  17%|█▋        | 85/500 [00:13<01:08,  6.08it/s, loss=0.449, v_num=0, train_loss_step=0.265]Epoch 0:  17%|█▋        | 86/500 [00:14<01:08,  6.08it/s, loss=0.449, v_num=0, train_loss_step=0.265]Epoch 0:  17%|█▋        | 86/500 [00:14<01:08,  6.08it/s, loss=0.451, v_num=0, train_loss_step=0.425]Epoch 0:  17%|█▋        | 87/500 [00:14<01:08,  6.07it/s, loss=0.451, v_num=0, train_loss_step=0.425]Epoch 0:  17%|█▋        | 87/500 [00:14<01:08,  6.07it/s, loss=0.42, v_num=0, train_loss_step=0.409] Epoch 0:  18%|█▊        | 88/500 [00:14<01:07,  6.07it/s, loss=0.42, v_num=0, train_loss_step=0.409]Epoch 0:  18%|█▊        | 88/500 [00:14<01:07,  6.07it/s, loss=0.411, v_num=0, train_loss_step=0.423]Epoch 0:  18%|█▊        | 89/500 [00:14<01:07,  6.07it/s, loss=0.411, v_num=0, train_loss_step=0.423]Epoch 0:  18%|█▊        | 89/500 [00:14<01:07,  6.07it/s, loss=0.387, v_num=0, train_loss_step=0.536]Epoch 0:  18%|█▊        | 90/500 [00:14<01:07,  6.07it/s, loss=0.387, v_num=0, train_loss_step=0.536]Epoch 0:  18%|█▊        | 90/500 [00:14<01:07,  6.07it/s, loss=0.379, v_num=0, train_loss_step=0.510]Epoch 0:  18%|█▊        | 91/500 [00:15<01:07,  6.06it/s, loss=0.379, v_num=0, train_loss_step=0.510]Epoch 0:  18%|█▊        | 91/500 [00:15<01:07,  6.06it/s, loss=0.366, v_num=0, train_loss_step=0.339]Epoch 0:  18%|█▊        | 92/500 [00:15<01:07,  6.07it/s, loss=0.366, v_num=0, train_loss_step=0.339]Epoch 0:  18%|█▊        | 92/500 [00:15<01:07,  6.07it/s, loss=0.372, v_num=0, train_loss_step=0.489]Epoch 0:  19%|█▊        | 93/500 [00:15<01:07,  6.07it/s, loss=0.372, v_num=0, train_loss_step=0.489]Epoch 0:  19%|█▊        | 93/500 [00:15<01:07,  6.06it/s, loss=0.387, v_num=0, train_loss_step=0.360]Epoch 0:  19%|█▉        | 94/500 [00:15<01:06,  6.06it/s, loss=0.387, v_num=0, train_loss_step=0.360]Epoch 0:  19%|█▉        | 94/500 [00:15<01:06,  6.06it/s, loss=0.377, v_num=0, train_loss_step=0.276]Epoch 0:  19%|█▉        | 95/500 [00:15<01:06,  6.07it/s, loss=0.377, v_num=0, train_loss_step=0.276]Epoch 0:  19%|█▉        | 95/500 [00:15<01:06,  6.07it/s, loss=0.378, v_num=0, train_loss_step=0.328]Epoch 0:  19%|█▉        | 96/500 [00:15<01:06,  6.06it/s, loss=0.378, v_num=0, train_loss_step=0.328]Epoch 0:  19%|█▉        | 96/500 [00:15<01:06,  6.06it/s, loss=0.394, v_num=0, train_loss_step=0.507]Epoch 0:  19%|█▉        | 97/500 [00:16<01:06,  6.06it/s, loss=0.394, v_num=0, train_loss_step=0.507]Epoch 0:  19%|█▉        | 97/500 [00:16<01:06,  6.06it/s, loss=0.381, v_num=0, train_loss_step=0.332]Epoch 0:  20%|█▉        | 98/500 [00:16<01:06,  6.07it/s, loss=0.381, v_num=0, train_loss_step=0.332]Epoch 0:  20%|█▉        | 98/500 [00:16<01:06,  6.07it/s, loss=0.373, v_num=0, train_loss_step=0.299]Epoch 0:  20%|█▉        | 99/500 [00:16<01:06,  6.06it/s, loss=0.373, v_num=0, train_loss_step=0.299]Epoch 0:  20%|█▉        | 99/500 [00:16<01:06,  6.06it/s, loss=0.359, v_num=0, train_loss_step=0.322]Epoch 0:  20%|██        | 100/500 [00:16<01:05,  6.06it/s, loss=0.359, v_num=0, train_loss_step=0.322]Epoch 0:  20%|██        | 100/500 [00:16<01:05,  6.06it/s, loss=0.361, v_num=0, train_loss_step=0.482]Epoch 0:  20%|██        | 101/500 [00:16<01:05,  6.06it/s, loss=0.361, v_num=0, train_loss_step=0.482]Epoch 0:  20%|██        | 101/500 [00:16<01:05,  6.06it/s, loss=0.374, v_num=0, train_loss_step=0.313]Epoch 0:  20%|██        | 102/500 [00:16<01:05,  6.06it/s, loss=0.374, v_num=0, train_loss_step=0.313]Epoch 0:  20%|██        | 102/500 [00:16<01:05,  6.06it/s, loss=0.354, v_num=0, train_loss_step=0.483]Epoch 0:  21%|██        | 103/500 [00:17<01:05,  6.05it/s, loss=0.354, v_num=0, train_loss_step=0.483]Epoch 0:  21%|██        | 103/500 [00:17<01:05,  6.05it/s, loss=0.339, v_num=0, train_loss_step=0.342]Epoch 0:  21%|██        | 104/500 [00:17<01:05,  6.06it/s, loss=0.339, v_num=0, train_loss_step=0.342]Epoch 0:  21%|██        | 104/500 [00:17<01:05,  6.06it/s, loss=0.342, v_num=0, train_loss_step=0.528]Epoch 0:  21%|██        | 105/500 [00:17<01:05,  6.07it/s, loss=0.342, v_num=0, train_loss_step=0.528]Epoch 0:  21%|██        | 105/500 [00:17<01:05,  6.07it/s, loss=0.351, v_num=0, train_loss_step=0.332]Epoch 0:  21%|██        | 106/500 [00:17<01:04,  6.07it/s, loss=0.351, v_num=0, train_loss_step=0.332]Epoch 0:  21%|██        | 106/500 [00:17<01:04,  6.07it/s, loss=0.318, v_num=0, train_loss_step=0.240]Epoch 0:  21%|██▏       | 107/500 [00:17<01:04,  6.08it/s, loss=0.318, v_num=0, train_loss_step=0.240]Epoch 0:  21%|██▏       | 107/500 [00:17<01:04,  6.08it/s, loss=0.326, v_num=0, train_loss_step=0.268]Epoch 0:  22%|██▏       | 108/500 [00:17<01:04,  6.07it/s, loss=0.326, v_num=0, train_loss_step=0.268]Epoch 0:  22%|██▏       | 108/500 [00:17<01:04,  6.07it/s, loss=0.313, v_num=0, train_loss_step=0.561]Epoch 0:  22%|██▏       | 109/500 [00:17<01:04,  6.07it/s, loss=0.313, v_num=0, train_loss_step=0.561]Epoch 0:  22%|██▏       | 109/500 [00:17<01:04,  6.07it/s, loss=0.336, v_num=0, train_loss_step=0.434]Epoch 0:  22%|██▏       | 110/500 [00:18<01:04,  6.08it/s, loss=0.336, v_num=0, train_loss_step=0.434]Epoch 0:  22%|██▏       | 110/500 [00:18<01:04,  6.08it/s, loss=0.333, v_num=0, train_loss_step=0.336]Epoch 0:  22%|██▏       | 111/500 [00:18<01:04,  6.07it/s, loss=0.333, v_num=0, train_loss_step=0.336]Epoch 0:  22%|██▏       | 111/500 [00:18<01:04,  6.07it/s, loss=0.347, v_num=0, train_loss_step=0.263]Epoch 0:  22%|██▏       | 112/500 [00:18<01:03,  6.07it/s, loss=0.347, v_num=0, train_loss_step=0.263]Epoch 0:  22%|██▏       | 112/500 [00:18<01:03,  6.07it/s, loss=0.347, v_num=0, train_loss_step=0.474]Epoch 0:  23%|██▎       | 113/500 [00:18<01:03,  6.07it/s, loss=0.347, v_num=0, train_loss_step=0.474]Epoch 0:  23%|██▎       | 113/500 [00:18<01:03,  6.07it/s, loss=0.316, v_num=0, train_loss_step=0.275]Epoch 0:  23%|██▎       | 114/500 [00:18<01:03,  6.08it/s, loss=0.316, v_num=0, train_loss_step=0.275]Epoch 0:  23%|██▎       | 114/500 [00:18<01:03,  6.08it/s, loss=0.328, v_num=0, train_loss_step=0.506]Epoch 0:  23%|██▎       | 115/500 [00:18<01:03,  6.08it/s, loss=0.328, v_num=0, train_loss_step=0.506]Epoch 0:  23%|██▎       | 115/500 [00:18<01:03,  6.08it/s, loss=0.31, v_num=0, train_loss_step=0.254] Epoch 0:  23%|██▎       | 116/500 [00:19<01:03,  6.08it/s, loss=0.31, v_num=0, train_loss_step=0.254]Epoch 0:  23%|██▎       | 116/500 [00:19<01:03,  6.08it/s, loss=0.288, v_num=0, train_loss_step=0.439]Epoch 0:  23%|██▎       | 117/500 [00:19<01:03,  6.08it/s, loss=0.288, v_num=0, train_loss_step=0.439]Epoch 0:  23%|██▎       | 117/500 [00:19<01:03,  6.08it/s, loss=0.285, v_num=0, train_loss_step=0.157]Epoch 0:  24%|██▎       | 118/500 [00:19<01:02,  6.07it/s, loss=0.285, v_num=0, train_loss_step=0.157]Epoch 0:  24%|██▎       | 118/500 [00:19<01:02,  6.07it/s, loss=0.282, v_num=0, train_loss_step=0.336]Epoch 0:  24%|██▍       | 119/500 [00:19<01:02,  6.07it/s, loss=0.282, v_num=0, train_loss_step=0.336]Epoch 0:  24%|██▍       | 119/500 [00:19<01:02,  6.07it/s, loss=0.281, v_num=0, train_loss_step=0.303]Epoch 0:  24%|██▍       | 120/500 [00:19<01:02,  6.07it/s, loss=0.281, v_num=0, train_loss_step=0.303]Epoch 0:  24%|██▍       | 120/500 [00:19<01:02,  6.07it/s, loss=0.265, v_num=0, train_loss_step=0.483]Epoch 0:  24%|██▍       | 121/500 [00:19<01:02,  6.06it/s, loss=0.265, v_num=0, train_loss_step=0.483]Epoch 0:  24%|██▍       | 121/500 [00:19<01:02,  6.06it/s, loss=0.266, v_num=0, train_loss_step=0.413]Epoch 0:  24%|██▍       | 122/500 [00:20<01:02,  6.08it/s, loss=0.266, v_num=0, train_loss_step=0.413]Epoch 0:  24%|██▍       | 122/500 [00:20<01:02,  6.08it/s, loss=0.27, v_num=0, train_loss_step=0.326] Epoch 0:  25%|██▍       | 123/500 [00:20<01:01,  6.08it/s, loss=0.27, v_num=0, train_loss_step=0.326]Epoch 0:  25%|██▍       | 123/500 [00:20<01:01,  6.08it/s, loss=0.295, v_num=0, train_loss_step=0.504]Epoch 0:  25%|██▍       | 124/500 [00:20<01:01,  6.08it/s, loss=0.295, v_num=0, train_loss_step=0.504]Epoch 0:  25%|██▍       | 124/500 [00:20<01:01,  6.08it/s, loss=0.296, v_num=0, train_loss_step=0.385]Epoch 0:  25%|██▌       | 125/500 [00:20<01:01,  6.10it/s, loss=0.296, v_num=0, train_loss_step=0.385]Epoch 0:  25%|██▌       | 125/500 [00:20<01:01,  6.10it/s, loss=0.318, v_num=0, train_loss_step=0.396]Epoch 0:  25%|██▌       | 126/500 [00:20<01:01,  6.09it/s, loss=0.318, v_num=0, train_loss_step=0.396]Epoch 0:  25%|██▌       | 126/500 [00:20<01:01,  6.09it/s, loss=0.332, v_num=0, train_loss_step=0.358]Epoch 0:  25%|██▌       | 127/500 [00:20<01:01,  6.09it/s, loss=0.332, v_num=0, train_loss_step=0.358]Epoch 0:  25%|██▌       | 127/500 [00:20<01:01,  6.09it/s, loss=0.36, v_num=0, train_loss_step=0.397] Epoch 0:  26%|██▌       | 128/500 [00:21<01:01,  6.09it/s, loss=0.36, v_num=0, train_loss_step=0.397]Epoch 0:  26%|██▌       | 128/500 [00:21<01:01,  6.09it/s, loss=0.38, v_num=0, train_loss_step=0.315]Epoch 0:  26%|██▌       | 129/500 [00:21<01:00,  6.08it/s, loss=0.38, v_num=0, train_loss_step=0.315]Epoch 0:  26%|██▌       | 129/500 [00:21<01:00,  6.08it/s, loss=0.348, v_num=0, train_loss_step=0.384]Epoch 0:  26%|██▌       | 130/500 [00:21<01:00,  6.08it/s, loss=0.348, v_num=0, train_loss_step=0.384]Epoch 0:  26%|██▌       | 130/500 [00:21<01:00,  6.08it/s, loss=0.356, v_num=0, train_loss_step=0.231]Epoch 0:  26%|██▌       | 131/500 [00:21<01:00,  6.09it/s, loss=0.356, v_num=0, train_loss_step=0.231]Epoch 0:  26%|██▌       | 131/500 [00:21<01:00,  6.09it/s, loss=0.366, v_num=0, train_loss_step=0.405]Epoch 0:  26%|██▋       | 132/500 [00:21<01:00,  6.09it/s, loss=0.366, v_num=0, train_loss_step=0.405]Epoch 0:  26%|██▋       | 132/500 [00:21<01:00,  6.09it/s, loss=0.371, v_num=0, train_loss_step=0.435]Epoch 0:  27%|██▋       | 133/500 [00:21<01:00,  6.08it/s, loss=0.371, v_num=0, train_loss_step=0.435]Epoch 0:  27%|██▋       | 133/500 [00:21<01:00,  6.08it/s, loss=0.384, v_num=0, train_loss_step=0.346]Epoch 0:  27%|██▋       | 134/500 [00:22<01:00,  6.08it/s, loss=0.384, v_num=0, train_loss_step=0.346]Epoch 0:  27%|██▋       | 134/500 [00:22<01:00,  6.08it/s, loss=0.406, v_num=0, train_loss_step=0.550]Epoch 0:  27%|██▋       | 135/500 [00:22<01:00,  6.08it/s, loss=0.406, v_num=0, train_loss_step=0.550]Epoch 0:  27%|██▋       | 135/500 [00:22<01:00,  6.08it/s, loss=0.404, v_num=0, train_loss_step=0.269]Epoch 0:  27%|██▋       | 136/500 [00:22<01:00,  6.05it/s, loss=0.404, v_num=0, train_loss_step=0.269]Epoch 0:  27%|██▋       | 136/500 [00:22<01:00,  6.05it/s, loss=0.404, v_num=0, train_loss_step=0.368]Epoch 0:  27%|██▋       | 137/500 [00:22<01:00,  6.05it/s, loss=0.404, v_num=0, train_loss_step=0.368]Epoch 0:  27%|██▋       | 137/500 [00:22<01:00,  6.05it/s, loss=0.408, v_num=0, train_loss_step=0.310]Epoch 0:  28%|██▊       | 138/500 [00:22<00:59,  6.04it/s, loss=0.408, v_num=0, train_loss_step=0.310]Epoch 0:  28%|██▊       | 138/500 [00:22<00:59,  6.04it/s, loss=0.419, v_num=0, train_loss_step=0.307]Epoch 0:  28%|██▊       | 139/500 [00:22<00:59,  6.05it/s, loss=0.419, v_num=0, train_loss_step=0.307]Epoch 0:  28%|██▊       | 139/500 [00:22<00:59,  6.05it/s, loss=0.421, v_num=0, train_loss_step=0.307]Epoch 0:  28%|██▊       | 140/500 [00:23<00:59,  6.06it/s, loss=0.421, v_num=0, train_loss_step=0.307]Epoch 0:  28%|██▊       | 140/500 [00:23<00:59,  6.06it/s, loss=0.43, v_num=0, train_loss_step=0.259] Epoch 0:  28%|██▊       | 141/500 [00:23<00:59,  6.06it/s, loss=0.43, v_num=0, train_loss_step=0.259]Epoch 0:  28%|██▊       | 141/500 [00:23<00:59,  6.06it/s, loss=0.428, v_num=0, train_loss_step=0.347]Epoch 0:  28%|██▊       | 142/500 [00:23<00:59,  6.06it/s, loss=0.428, v_num=0, train_loss_step=0.347]Epoch 0:  28%|██▊       | 142/500 [00:23<00:59,  6.06it/s, loss=0.419, v_num=0, train_loss_step=0.338]Epoch 0:  29%|██▊       | 143/500 [00:23<00:58,  6.07it/s, loss=0.419, v_num=0, train_loss_step=0.338]Epoch 0:  29%|██▊       | 143/500 [00:23<00:58,  6.07it/s, loss=0.395, v_num=0, train_loss_step=0.317]Epoch 0:  29%|██▉       | 144/500 [00:23<00:58,  6.08it/s, loss=0.395, v_num=0, train_loss_step=0.317]Epoch 0:  29%|██▉       | 144/500 [00:23<00:58,  6.08it/s, loss=0.405, v_num=0, train_loss_step=0.323]Epoch 0:  29%|██▉       | 145/500 [00:23<00:58,  6.07it/s, loss=0.405, v_num=0, train_loss_step=0.323]Epoch 0:  29%|██▉       | 145/500 [00:23<00:58,  6.07it/s, loss=0.38, v_num=0, train_loss_step=0.293] Epoch 0:  29%|██▉       | 146/500 [00:24<00:58,  6.08it/s, loss=0.38, v_num=0, train_loss_step=0.293]Epoch 0:  29%|██▉       | 146/500 [00:24<00:58,  6.08it/s, loss=0.38, v_num=0, train_loss_step=0.289]Epoch 0:  29%|██▉       | 147/500 [00:24<00:58,  6.08it/s, loss=0.38, v_num=0, train_loss_step=0.289]Epoch 0:  29%|██▉       | 147/500 [00:24<00:58,  6.08it/s, loss=0.353, v_num=0, train_loss_step=0.243]Epoch 0:  30%|██▉       | 148/500 [00:24<00:57,  6.08it/s, loss=0.353, v_num=0, train_loss_step=0.243]Epoch 0:  30%|██▉       | 148/500 [00:24<00:57,  6.08it/s, loss=0.334, v_num=0, train_loss_step=0.284]Epoch 0:  30%|██▉       | 149/500 [00:24<00:57,  6.09it/s, loss=0.334, v_num=0, train_loss_step=0.284]Epoch 0:  30%|██▉       | 149/500 [00:24<00:57,  6.09it/s, loss=0.353, v_num=0, train_loss_step=0.531]Epoch 0:  30%|███       | 150/500 [00:24<00:57,  6.10it/s, loss=0.353, v_num=0, train_loss_step=0.531]Epoch 0:  30%|███       | 150/500 [00:24<00:57,  6.10it/s, loss=0.377, v_num=0, train_loss_step=0.569]Epoch 0:  30%|███       | 151/500 [00:24<00:57,  6.09it/s, loss=0.377, v_num=0, train_loss_step=0.569]Epoch 0:  30%|███       | 151/500 [00:24<00:57,  6.09it/s, loss=0.351, v_num=0, train_loss_step=0.147]Epoch 0:  30%|███       | 152/500 [00:25<00:57,  6.07it/s, loss=0.351, v_num=0, train_loss_step=0.147]Epoch 0:  30%|███       | 152/500 [00:25<00:57,  6.07it/s, loss=0.339, v_num=0, train_loss_step=0.277]Epoch 0:  31%|███       | 153/500 [00:25<00:57,  6.07it/s, loss=0.339, v_num=0, train_loss_step=0.277]Epoch 0:  31%|███       | 153/500 [00:25<00:57,  6.07it/s, loss=0.328, v_num=0, train_loss_step=0.155]Epoch 0:  31%|███       | 154/500 [00:25<00:56,  6.07it/s, loss=0.328, v_num=0, train_loss_step=0.155]Epoch 0:  31%|███       | 154/500 [00:25<00:57,  6.07it/s, loss=0.293, v_num=0, train_loss_step=0.255]Epoch 0:  31%|███       | 155/500 [00:25<00:56,  6.08it/s, loss=0.293, v_num=0, train_loss_step=0.255]Epoch 0:  31%|███       | 155/500 [00:25<00:56,  6.08it/s, loss=0.296, v_num=0, train_loss_step=0.191]Epoch 0:  31%|███       | 156/500 [00:25<00:56,  6.07it/s, loss=0.296, v_num=0, train_loss_step=0.191]Epoch 0:  31%|███       | 156/500 [00:25<00:56,  6.07it/s, loss=0.298, v_num=0, train_loss_step=0.246]Epoch 0:  31%|███▏      | 157/500 [00:25<00:56,  6.07it/s, loss=0.298, v_num=0, train_loss_step=0.246]Epoch 0:  31%|███▏      | 157/500 [00:25<00:56,  6.07it/s, loss=0.296, v_num=0, train_loss_step=0.288]Epoch 0:  32%|███▏      | 158/500 [00:26<00:56,  6.07it/s, loss=0.296, v_num=0, train_loss_step=0.288]Epoch 0:  32%|███▏      | 158/500 [00:26<00:56,  6.07it/s, loss=0.278, v_num=0, train_loss_step=0.286]Epoch 0:  32%|███▏      | 159/500 [00:26<00:56,  6.07it/s, loss=0.278, v_num=0, train_loss_step=0.286]Epoch 0:  32%|███▏      | 159/500 [00:26<00:56,  6.07it/s, loss=0.286, v_num=0, train_loss_step=0.274]Epoch 0:  32%|███▏      | 160/500 [00:26<00:56,  6.05it/s, loss=0.286, v_num=0, train_loss_step=0.274]Epoch 0:  32%|███▏      | 160/500 [00:26<00:56,  6.05it/s, loss=0.289, v_num=0, train_loss_step=0.183]Epoch 0:  32%|███▏      | 161/500 [00:26<00:56,  6.05it/s, loss=0.289, v_num=0, train_loss_step=0.183]Epoch 0:  32%|███▏      | 161/500 [00:26<00:56,  6.05it/s, loss=0.279, v_num=0, train_loss_step=0.162]Epoch 0:  32%|███▏      | 162/500 [00:26<00:55,  6.06it/s, loss=0.279, v_num=0, train_loss_step=0.162]Epoch 0:  32%|███▏      | 162/500 [00:26<00:55,  6.06it/s, loss=0.286, v_num=0, train_loss_step=0.281]Epoch 0:  33%|███▎      | 163/500 [00:26<00:55,  6.05it/s, loss=0.286, v_num=0, train_loss_step=0.281]Epoch 0:  33%|███▎      | 163/500 [00:26<00:55,  6.05it/s, loss=0.279, v_num=0, train_loss_step=0.160]Epoch 0:  33%|███▎      | 164/500 [00:27<00:55,  6.05it/s, loss=0.279, v_num=0, train_loss_step=0.160]Epoch 0:  33%|███▎      | 164/500 [00:27<00:55,  6.05it/s, loss=0.26, v_num=0, train_loss_step=0.237] Epoch 0:  33%|███▎      | 165/500 [00:27<00:55,  6.06it/s, loss=0.26, v_num=0, train_loss_step=0.237]Epoch 0:  33%|███▎      | 165/500 [00:27<00:55,  6.06it/s, loss=0.253, v_num=0, train_loss_step=0.398]Epoch 0:  33%|███▎      | 166/500 [00:27<00:55,  6.06it/s, loss=0.253, v_num=0, train_loss_step=0.398]Epoch 0:  33%|███▎      | 166/500 [00:27<00:55,  6.06it/s, loss=0.252, v_num=0, train_loss_step=0.470]Epoch 0:  33%|███▎      | 167/500 [00:27<00:54,  6.07it/s, loss=0.252, v_num=0, train_loss_step=0.470]Epoch 0:  33%|███▎      | 167/500 [00:27<00:54,  6.07it/s, loss=0.247, v_num=0, train_loss_step=0.309]Epoch 0:  34%|███▎      | 168/500 [00:27<00:54,  6.06it/s, loss=0.247, v_num=0, train_loss_step=0.309]Epoch 0:  34%|███▎      | 168/500 [00:27<00:54,  6.06it/s, loss=0.252, v_num=0, train_loss_step=0.310]Epoch 0:  34%|███▍      | 169/500 [00:27<00:54,  6.06it/s, loss=0.252, v_num=0, train_loss_step=0.310]Epoch 0:  34%|███▍      | 169/500 [00:27<00:54,  6.06it/s, loss=0.234, v_num=0, train_loss_step=0.323]Epoch 0:  34%|███▍      | 170/500 [00:28<00:54,  6.06it/s, loss=0.234, v_num=0, train_loss_step=0.323]Epoch 0:  34%|███▍      | 170/500 [00:28<00:54,  6.06it/s, loss=0.201, v_num=0, train_loss_step=0.179]Epoch 0:  34%|███▍      | 171/500 [00:28<00:54,  6.06it/s, loss=0.201, v_num=0, train_loss_step=0.179]Epoch 0:  34%|███▍      | 171/500 [00:28<00:54,  6.06it/s, loss=0.199, v_num=0, train_loss_step=0.151]Epoch 0:  34%|███▍      | 172/500 [00:28<00:54,  6.07it/s, loss=0.199, v_num=0, train_loss_step=0.151]Epoch 0:  34%|███▍      | 172/500 [00:28<00:54,  6.07it/s, loss=0.199, v_num=0, train_loss_step=0.279]Epoch 0:  35%|███▍      | 173/500 [00:28<00:53,  6.08it/s, loss=0.199, v_num=0, train_loss_step=0.279]Epoch 0:  35%|███▍      | 173/500 [00:28<00:53,  6.08it/s, loss=0.218, v_num=0, train_loss_step=0.285]Epoch 0:  35%|███▍      | 174/500 [00:28<00:53,  6.08it/s, loss=0.218, v_num=0, train_loss_step=0.285]Epoch 0:  35%|███▍      | 174/500 [00:28<00:53,  6.08it/s, loss=0.216, v_num=0, train_loss_step=0.217]Epoch 0:  35%|███▌      | 175/500 [00:28<00:53,  6.09it/s, loss=0.216, v_num=0, train_loss_step=0.217]Epoch 0:  35%|███▌      | 175/500 [00:28<00:53,  6.09it/s, loss=0.22, v_num=0, train_loss_step=0.259] Epoch 0:  35%|███▌      | 176/500 [00:29<00:53,  6.07it/s, loss=0.22, v_num=0, train_loss_step=0.259]Epoch 0:  35%|███▌      | 176/500 [00:29<00:53,  6.07it/s, loss=0.213, v_num=0, train_loss_step=0.176]Epoch 0:  35%|███▌      | 177/500 [00:29<00:53,  6.07it/s, loss=0.213, v_num=0, train_loss_step=0.176]Epoch 0:  35%|███▌      | 177/500 [00:29<00:53,  6.07it/s, loss=0.221, v_num=0, train_loss_step=0.218]Epoch 0:  36%|███▌      | 178/500 [00:29<00:53,  6.07it/s, loss=0.221, v_num=0, train_loss_step=0.218]Epoch 0:  36%|███▌      | 178/500 [00:29<00:53,  6.07it/s, loss=0.229, v_num=0, train_loss_step=0.192]Epoch 0:  36%|███▌      | 179/500 [00:29<00:52,  6.08it/s, loss=0.229, v_num=0, train_loss_step=0.192]Epoch 0:  36%|███▌      | 179/500 [00:29<00:52,  6.08it/s, loss=0.217, v_num=0, train_loss_step=0.135]Epoch 0:  36%|███▌      | 180/500 [00:29<00:52,  6.08it/s, loss=0.217, v_num=0, train_loss_step=0.135]Epoch 0:  36%|███▌      | 180/500 [00:29<00:52,  6.08it/s, loss=0.22, v_num=0, train_loss_step=0.198] Epoch 0:  36%|███▌      | 181/500 [00:29<00:52,  6.08it/s, loss=0.22, v_num=0, train_loss_step=0.198]Epoch 0:  36%|███▌      | 181/500 [00:29<00:52,  6.08it/s, loss=0.23, v_num=0, train_loss_step=0.218]Epoch 0:  36%|███▋      | 182/500 [00:29<00:52,  6.09it/s, loss=0.23, v_num=0, train_loss_step=0.218]Epoch 0:  36%|███▋      | 182/500 [00:29<00:52,  6.09it/s, loss=0.229, v_num=0, train_loss_step=0.184]Epoch 0:  37%|███▋      | 183/500 [00:30<00:52,  6.09it/s, loss=0.229, v_num=0, train_loss_step=0.184]Epoch 0:  37%|███▋      | 183/500 [00:30<00:52,  6.09it/s, loss=0.229, v_num=0, train_loss_step=0.178]Epoch 0:  37%|███▋      | 184/500 [00:30<00:52,  6.07it/s, loss=0.229, v_num=0, train_loss_step=0.178]Epoch 0:  37%|███▋      | 184/500 [00:30<00:52,  6.07it/s, loss=0.233, v_num=0, train_loss_step=0.250]Epoch 0:  37%|███▋      | 185/500 [00:30<00:51,  6.07it/s, loss=0.233, v_num=0, train_loss_step=0.250]Epoch 0:  37%|███▋      | 185/500 [00:30<00:51,  6.07it/s, loss=0.23, v_num=0, train_loss_step=0.212] Epoch 0:  37%|███▋      | 186/500 [00:30<00:51,  6.07it/s, loss=0.23, v_num=0, train_loss_step=0.212]Epoch 0:  37%|███▋      | 186/500 [00:30<00:51,  6.07it/s, loss=0.225, v_num=0, train_loss_step=0.249]Epoch 0:  37%|███▋      | 187/500 [00:30<00:51,  6.07it/s, loss=0.225, v_num=0, train_loss_step=0.249]Epoch 0:  37%|███▋      | 187/500 [00:30<00:51,  6.07it/s, loss=0.218, v_num=0, train_loss_step=0.156]Epoch 0:  38%|███▊      | 188/500 [00:30<00:51,  6.08it/s, loss=0.218, v_num=0, train_loss_step=0.156]Epoch 0:  38%|███▊      | 188/500 [00:30<00:51,  6.08it/s, loss=0.216, v_num=0, train_loss_step=0.302]Epoch 0:  38%|███▊      | 189/500 [00:31<00:51,  6.09it/s, loss=0.216, v_num=0, train_loss_step=0.302]Epoch 0:  38%|███▊      | 189/500 [00:31<00:51,  6.09it/s, loss=0.222, v_num=0, train_loss_step=0.355]Epoch 0:  38%|███▊      | 190/500 [00:31<00:50,  6.09it/s, loss=0.222, v_num=0, train_loss_step=0.355]Epoch 0:  38%|███▊      | 190/500 [00:31<00:50,  6.09it/s, loss=0.228, v_num=0, train_loss_step=0.243]Epoch 0:  38%|███▊      | 191/500 [00:31<00:50,  6.09it/s, loss=0.228, v_num=0, train_loss_step=0.243]Epoch 0:  38%|███▊      | 191/500 [00:31<00:50,  6.09it/s, loss=0.231, v_num=0, train_loss_step=0.212]Epoch 0:  38%|███▊      | 192/500 [00:31<00:50,  6.07it/s, loss=0.231, v_num=0, train_loss_step=0.212]Epoch 0:  38%|███▊      | 192/500 [00:31<00:50,  6.07it/s, loss=0.229, v_num=0, train_loss_step=0.176]Epoch 0:  39%|███▊      | 193/500 [00:31<00:50,  6.07it/s, loss=0.229, v_num=0, train_loss_step=0.176]Epoch 0:  39%|███▊      | 193/500 [00:31<00:50,  6.07it/s, loss=0.212, v_num=0, train_loss_step=0.180]Epoch 0:  39%|███▉      | 194/500 [00:31<00:50,  6.07it/s, loss=0.212, v_num=0, train_loss_step=0.180]Epoch 0:  39%|███▉      | 194/500 [00:31<00:50,  6.07it/s, loss=0.224, v_num=0, train_loss_step=0.224]Epoch 0:  39%|███▉      | 195/500 [00:32<00:50,  6.07it/s, loss=0.224, v_num=0, train_loss_step=0.224]Epoch 0:  39%|███▉      | 195/500 [00:32<00:50,  6.07it/s, loss=0.215, v_num=0, train_loss_step=0.230]Epoch 0:  39%|███▉      | 196/500 [00:32<00:50,  6.07it/s, loss=0.215, v_num=0, train_loss_step=0.230]Epoch 0:  39%|███▉      | 196/500 [00:32<00:50,  6.07it/s, loss=0.212, v_num=0, train_loss_step=0.133]Epoch 0:  39%|███▉      | 197/500 [00:32<00:49,  6.07it/s, loss=0.212, v_num=0, train_loss_step=0.133]Epoch 0:  39%|███▉      | 197/500 [00:32<00:49,  6.07it/s, loss=0.207, v_num=0, train_loss_step=0.192]Epoch 0:  40%|███▉      | 198/500 [00:32<00:49,  6.07it/s, loss=0.207, v_num=0, train_loss_step=0.192]Epoch 0:  40%|███▉      | 198/500 [00:32<00:49,  6.07it/s, loss=0.2, v_num=0, train_loss_step=0.138]  Epoch 0:  40%|███▉      | 199/500 [00:32<00:49,  6.07it/s, loss=0.2, v_num=0, train_loss_step=0.138]Epoch 0:  40%|███▉      | 199/500 [00:32<00:49,  6.07it/s, loss=0.192, v_num=0, train_loss_step=0.228]Epoch 0:  40%|████      | 200/500 [00:32<00:49,  6.06it/s, loss=0.192, v_num=0, train_loss_step=0.228]Epoch 0:  40%|████      | 200/500 [00:32<00:49,  6.06it/s, loss=0.177, v_num=0, train_loss_step=0.175]Epoch 0:  40%|████      | 201/500 [00:33<00:49,  6.06it/s, loss=0.177, v_num=0, train_loss_step=0.175]Epoch 0:  40%|████      | 201/500 [00:33<00:49,  6.06it/s, loss=0.171, v_num=0, train_loss_step=0.226]Epoch 0:  40%|████      | 202/500 [00:33<00:49,  6.07it/s, loss=0.171, v_num=0, train_loss_step=0.226]Epoch 0:  40%|████      | 202/500 [00:33<00:49,  6.07it/s, loss=0.181, v_num=0, train_loss_step=0.313]Epoch 0:  41%|████      | 203/500 [00:33<00:48,  6.06it/s, loss=0.181, v_num=0, train_loss_step=0.313]Epoch 0:  41%|████      | 203/500 [00:33<00:48,  6.06it/s, loss=0.195, v_num=0, train_loss_step=0.222]Epoch 0:  41%|████      | 204/500 [00:33<00:48,  6.06it/s, loss=0.195, v_num=0, train_loss_step=0.222]Epoch 0:  41%|████      | 204/500 [00:33<00:48,  6.06it/s, loss=0.191, v_num=0, train_loss_step=0.136]Epoch 0:  41%|████      | 205/500 [00:33<00:48,  6.07it/s, loss=0.191, v_num=0, train_loss_step=0.136]Epoch 0:  41%|████      | 205/500 [00:33<00:48,  6.07it/s, loss=0.199, v_num=0, train_loss_step=0.220]Epoch 0:  41%|████      | 206/500 [00:33<00:48,  6.07it/s, loss=0.199, v_num=0, train_loss_step=0.220]Epoch 0:  41%|████      | 206/500 [00:33<00:48,  6.07it/s, loss=0.202, v_num=0, train_loss_step=0.187]Epoch 0:  41%|████▏     | 207/500 [00:34<00:48,  6.06it/s, loss=0.202, v_num=0, train_loss_step=0.187]Epoch 0:  41%|████▏     | 207/500 [00:34<00:48,  6.06it/s, loss=0.204, v_num=0, train_loss_step=0.125]Epoch 0:  42%|████▏     | 208/500 [00:34<00:48,  6.05it/s, loss=0.204, v_num=0, train_loss_step=0.125]Epoch 0:  42%|████▏     | 208/500 [00:34<00:48,  6.05it/s, loss=0.201, v_num=0, train_loss_step=0.122]Epoch 0:  42%|████▏     | 209/500 [00:34<00:48,  6.05it/s, loss=0.201, v_num=0, train_loss_step=0.122]Epoch 0:  42%|████▏     | 209/500 [00:34<00:48,  6.05it/s, loss=0.197, v_num=0, train_loss_step=0.191]Epoch 0:  42%|████▏     | 210/500 [00:34<00:47,  6.05it/s, loss=0.197, v_num=0, train_loss_step=0.191]Epoch 0:  42%|████▏     | 210/500 [00:34<00:47,  6.05it/s, loss=0.2, v_num=0, train_loss_step=0.175]  Epoch 0:  42%|████▏     | 211/500 [00:34<00:47,  6.05it/s, loss=0.2, v_num=0, train_loss_step=0.175]Epoch 0:  42%|████▏     | 211/500 [00:34<00:47,  6.05it/s, loss=0.201, v_num=0, train_loss_step=0.144]Epoch 0:  42%|████▏     | 212/500 [00:35<00:47,  6.05it/s, loss=0.201, v_num=0, train_loss_step=0.144]Epoch 0:  42%|████▏     | 212/500 [00:35<00:47,  6.05it/s, loss=0.201, v_num=0, train_loss_step=0.168]Epoch 0:  43%|████▎     | 213/500 [00:35<00:47,  6.05it/s, loss=0.201, v_num=0, train_loss_step=0.168]Epoch 0:  43%|████▎     | 213/500 [00:35<00:47,  6.05it/s, loss=0.203, v_num=0, train_loss_step=0.136]Epoch 0:  43%|████▎     | 214/500 [00:35<00:47,  6.05it/s, loss=0.203, v_num=0, train_loss_step=0.136]Epoch 0:  43%|████▎     | 214/500 [00:35<00:47,  6.05it/s, loss=0.194, v_num=0, train_loss_step=0.159]Epoch 0:  43%|████▎     | 215/500 [00:35<00:47,  6.05it/s, loss=0.194, v_num=0, train_loss_step=0.159]Epoch 0:  43%|████▎     | 215/500 [00:35<00:47,  6.05it/s, loss=0.194, v_num=0, train_loss_step=0.151]Epoch 0:  43%|████▎     | 216/500 [00:35<00:47,  6.04it/s, loss=0.194, v_num=0, train_loss_step=0.151]Epoch 0:  43%|████▎     | 216/500 [00:35<00:47,  6.04it/s, loss=0.196, v_num=0, train_loss_step=0.266]Epoch 0:  43%|████▎     | 217/500 [00:35<00:46,  6.04it/s, loss=0.196, v_num=0, train_loss_step=0.266]Epoch 0:  43%|████▎     | 217/500 [00:35<00:46,  6.04it/s, loss=0.191, v_num=0, train_loss_step=0.102]Epoch 0:  44%|████▎     | 218/500 [00:36<00:46,  6.04it/s, loss=0.191, v_num=0, train_loss_step=0.102]Epoch 0:  44%|████▎     | 218/500 [00:36<00:46,  6.04it/s, loss=0.193, v_num=0, train_loss_step=0.146]Epoch 0:  44%|████▍     | 219/500 [00:36<00:46,  6.04it/s, loss=0.193, v_num=0, train_loss_step=0.146]Epoch 0:  44%|████▍     | 219/500 [00:36<00:46,  6.04it/s, loss=0.196, v_num=0, train_loss_step=0.160]Epoch 0:  44%|████▍     | 220/500 [00:36<00:46,  6.04it/s, loss=0.196, v_num=0, train_loss_step=0.160]Epoch 0:  44%|████▍     | 220/500 [00:36<00:46,  6.04it/s, loss=0.195, v_num=0, train_loss_step=0.158]Epoch 0:  44%|████▍     | 221/500 [00:36<00:46,  6.04it/s, loss=0.195, v_num=0, train_loss_step=0.158]Epoch 0:  44%|████▍     | 221/500 [00:36<00:46,  6.04it/s, loss=0.194, v_num=0, train_loss_step=0.198]Epoch 0:  44%|████▍     | 222/500 [00:36<00:46,  6.04it/s, loss=0.194, v_num=0, train_loss_step=0.198]Epoch 0:  44%|████▍     | 222/500 [00:36<00:46,  6.04it/s, loss=0.192, v_num=0, train_loss_step=0.162]Epoch 0:  45%|████▍     | 223/500 [00:36<00:45,  6.04it/s, loss=0.192, v_num=0, train_loss_step=0.162]Epoch 0:  45%|████▍     | 223/500 [00:36<00:45,  6.04it/s, loss=0.179, v_num=0, train_loss_step=0.116]Epoch 0:  45%|████▍     | 224/500 [00:37<00:45,  6.03it/s, loss=0.179, v_num=0, train_loss_step=0.116]Epoch 0:  45%|████▍     | 224/500 [00:37<00:45,  6.03it/s, loss=0.194, v_num=0, train_loss_step=0.280]Epoch 0:  45%|████▌     | 225/500 [00:37<00:45,  6.03it/s, loss=0.194, v_num=0, train_loss_step=0.280]Epoch 0:  45%|████▌     | 225/500 [00:37<00:45,  6.03it/s, loss=0.191, v_num=0, train_loss_step=0.248]Epoch 0:  45%|████▌     | 226/500 [00:37<00:45,  6.04it/s, loss=0.191, v_num=0, train_loss_step=0.248]Epoch 0:  45%|████▌     | 226/500 [00:37<00:45,  6.04it/s, loss=0.183, v_num=0, train_loss_step=0.309]Epoch 0:  45%|████▌     | 227/500 [00:37<00:45,  6.04it/s, loss=0.183, v_num=0, train_loss_step=0.309]Epoch 0:  45%|████▌     | 227/500 [00:37<00:45,  6.04it/s, loss=0.184, v_num=0, train_loss_step=0.186]Epoch 0:  46%|████▌     | 228/500 [00:37<00:45,  6.04it/s, loss=0.184, v_num=0, train_loss_step=0.186]Epoch 0:  46%|████▌     | 228/500 [00:37<00:45,  6.04it/s, loss=0.183, v_num=0, train_loss_step=0.162]Epoch 0:  46%|████▌     | 229/500 [00:37<00:44,  6.04it/s, loss=0.183, v_num=0, train_loss_step=0.162]Epoch 0:  46%|████▌     | 229/500 [00:37<00:44,  6.04it/s, loss=0.183, v_num=0, train_loss_step=0.0942]Epoch 0:  46%|████▌     | 230/500 [00:38<00:44,  6.05it/s, loss=0.183, v_num=0, train_loss_step=0.0942]Epoch 0:  46%|████▌     | 230/500 [00:38<00:44,  6.05it/s, loss=0.177, v_num=0, train_loss_step=0.201] Epoch 0:  46%|████▌     | 231/500 [00:38<00:44,  6.05it/s, loss=0.177, v_num=0, train_loss_step=0.201]Epoch 0:  46%|████▌     | 231/500 [00:38<00:44,  6.05it/s, loss=0.179, v_num=0, train_loss_step=0.226]Epoch 0:  46%|████▋     | 232/500 [00:38<00:44,  6.04it/s, loss=0.179, v_num=0, train_loss_step=0.226]Epoch 0:  46%|████▋     | 232/500 [00:38<00:44,  6.04it/s, loss=0.181, v_num=0, train_loss_step=0.181]Epoch 0:  47%|████▋     | 233/500 [00:38<00:44,  6.04it/s, loss=0.181, v_num=0, train_loss_step=0.181]Epoch 0:  47%|████▋     | 233/500 [00:38<00:44,  6.04it/s, loss=0.172, v_num=0, train_loss_step=0.122]Epoch 0:  47%|████▋     | 234/500 [00:38<00:44,  6.04it/s, loss=0.172, v_num=0, train_loss_step=0.122]Epoch 0:  47%|████▋     | 234/500 [00:38<00:44,  6.04it/s, loss=0.17, v_num=0, train_loss_step=0.218] Epoch 0:  47%|████▋     | 235/500 [00:38<00:43,  6.04it/s, loss=0.17, v_num=0, train_loss_step=0.218]Epoch 0:  47%|████▋     | 235/500 [00:38<00:43,  6.04it/s, loss=0.169, v_num=0, train_loss_step=0.158]Epoch 0:  47%|████▋     | 236/500 [00:39<00:43,  6.04it/s, loss=0.169, v_num=0, train_loss_step=0.158]Epoch 0:  47%|████▋     | 236/500 [00:39<00:43,  6.04it/s, loss=0.167, v_num=0, train_loss_step=0.113]Epoch 0:  47%|████▋     | 237/500 [00:39<00:43,  6.05it/s, loss=0.167, v_num=0, train_loss_step=0.113]Epoch 0:  47%|████▋     | 237/500 [00:39<00:43,  6.05it/s, loss=0.17, v_num=0, train_loss_step=0.216] Epoch 0:  48%|████▊     | 238/500 [00:39<00:43,  6.05it/s, loss=0.17, v_num=0, train_loss_step=0.216]Epoch 0:  48%|████▊     | 238/500 [00:39<00:43,  6.05it/s, loss=0.171, v_num=0, train_loss_step=0.181]Epoch 0:  48%|████▊     | 239/500 [00:39<00:43,  6.05it/s, loss=0.171, v_num=0, train_loss_step=0.181]Epoch 0:  48%|████▊     | 239/500 [00:39<00:43,  6.05it/s, loss=0.166, v_num=0, train_loss_step=0.0922]Epoch 0:  48%|████▊     | 240/500 [00:39<00:43,  6.04it/s, loss=0.166, v_num=0, train_loss_step=0.0922]Epoch 0:  48%|████▊     | 240/500 [00:39<00:43,  6.04it/s, loss=0.166, v_num=0, train_loss_step=0.224] Epoch 0:  48%|████▊     | 241/500 [00:39<00:42,  6.04it/s, loss=0.166, v_num=0, train_loss_step=0.224]Epoch 0:  48%|████▊     | 241/500 [00:39<00:42,  6.04it/s, loss=0.164, v_num=0, train_loss_step=0.102]Epoch 0:  48%|████▊     | 242/500 [00:40<00:42,  6.04it/s, loss=0.164, v_num=0, train_loss_step=0.102]Epoch 0:  48%|████▊     | 242/500 [00:40<00:42,  6.04it/s, loss=0.157, v_num=0, train_loss_step=0.237]Epoch 0:  49%|████▊     | 243/500 [00:40<00:42,  6.04it/s, loss=0.157, v_num=0, train_loss_step=0.237]Epoch 0:  49%|████▊     | 243/500 [00:40<00:42,  6.04it/s, loss=0.166, v_num=0, train_loss_step=0.210]Epoch 0:  49%|████▉     | 244/500 [00:40<00:42,  6.04it/s, loss=0.166, v_num=0, train_loss_step=0.210]Epoch 0:  49%|████▉     | 244/500 [00:40<00:42,  6.04it/s, loss=0.151, v_num=0, train_loss_step=0.186]Epoch 0:  49%|████▉     | 245/500 [00:40<00:42,  6.04it/s, loss=0.151, v_num=0, train_loss_step=0.186]Epoch 0:  49%|████▉     | 245/500 [00:40<00:42,  6.04it/s, loss=0.143, v_num=0, train_loss_step=0.134]Epoch 0:  49%|████▉     | 246/500 [00:40<00:42,  6.04it/s, loss=0.143, v_num=0, train_loss_step=0.134]Epoch 0:  49%|████▉     | 246/500 [00:40<00:42,  6.04it/s, loss=0.144, v_num=0, train_loss_step=0.128]Epoch 0:  49%|████▉     | 247/500 [00:40<00:41,  6.04it/s, loss=0.144, v_num=0, train_loss_step=0.128]Epoch 0:  49%|████▉     | 247/500 [00:40<00:41,  6.04it/s, loss=0.141, v_num=0, train_loss_step=0.167]Epoch 0:  50%|████▉     | 248/500 [00:41<00:41,  6.02it/s, loss=0.141, v_num=0, train_loss_step=0.167]Epoch 0:  50%|████▉     | 248/500 [00:41<00:41,  6.02it/s, loss=0.139, v_num=0, train_loss_step=0.241]Epoch 0:  50%|████▉     | 249/500 [00:41<00:41,  6.02it/s, loss=0.139, v_num=0, train_loss_step=0.241]Epoch 0:  50%|████▉     | 249/500 [00:41<00:41,  6.02it/s, loss=0.135, v_num=0, train_loss_step=0.097]Epoch 0:  50%|█████     | 250/500 [00:41<00:41,  6.02it/s, loss=0.135, v_num=0, train_loss_step=0.097]Epoch 0:  50%|█████     | 250/500 [00:41<00:41,  6.02it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation: 0it [00:00, ?it/s][Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)

Validation:   0%|          | 0/250 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/250 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 1/250 [00:00<00:35,  7.09it/s][AEpoch 0:  50%|█████     | 251/500 [00:41<00:41,  6.00it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:   1%|          | 2/250 [00:00<00:23, 10.36it/s][AEpoch 0:  50%|█████     | 252/500 [00:41<00:41,  6.02it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:   1%|          | 3/250 [00:00<00:18, 13.63it/s][AEpoch 0:  51%|█████     | 253/500 [00:41<00:40,  6.04it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:   2%|▏         | 4/250 [00:00<00:16, 15.16it/s][AEpoch 0:  51%|█████     | 254/500 [00:41<00:40,  6.05it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:   2%|▏         | 5/250 [00:00<00:15, 16.23it/s][AEpoch 0:  51%|█████     | 255/500 [00:41<00:40,  6.07it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:   2%|▏         | 6/250 [00:00<00:13, 17.79it/s][AEpoch 0:  51%|█████     | 256/500 [00:42<00:40,  6.09it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:   3%|▎         | 7/250 [00:00<00:12, 19.03it/s][AEpoch 0:  51%|█████▏    | 257/500 [00:42<00:39,  6.11it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:   3%|▎         | 8/250 [00:00<00:11, 20.30it/s][AEpoch 0:  52%|█████▏    | 258/500 [00:42<00:39,  6.13it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:   4%|▎         | 9/250 [00:00<00:11, 20.55it/s][AEpoch 0:  52%|█████▏    | 259/500 [00:42<00:39,  6.15it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:   4%|▍         | 10/250 [00:00<00:11, 20.75it/s][AEpoch 0:  52%|█████▏    | 260/500 [00:42<00:38,  6.17it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:   4%|▍         | 11/250 [00:00<00:11, 20.87it/s][AEpoch 0:  52%|█████▏    | 261/500 [00:42<00:38,  6.18it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:   5%|▍         | 12/250 [00:00<00:11, 21.45it/s][AEpoch 0:  52%|█████▏    | 262/500 [00:42<00:38,  6.20it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:   5%|▌         | 13/250 [00:00<00:11, 21.46it/s][AEpoch 0:  53%|█████▎    | 263/500 [00:42<00:38,  6.22it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:   6%|▌         | 14/250 [00:00<00:10, 21.93it/s][AEpoch 0:  53%|█████▎    | 264/500 [00:42<00:37,  6.24it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:   6%|▌         | 15/250 [00:00<00:10, 21.98it/s][AEpoch 0:  53%|█████▎    | 265/500 [00:42<00:37,  6.25it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:   6%|▋         | 16/250 [00:00<00:10, 22.34it/s][AEpoch 0:  53%|█████▎    | 266/500 [00:42<00:37,  6.27it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:   7%|▋         | 17/250 [00:00<00:10, 22.37it/s][AEpoch 0:  53%|█████▎    | 267/500 [00:42<00:37,  6.29it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:   7%|▋         | 18/250 [00:00<00:10, 22.73it/s][AEpoch 0:  54%|█████▎    | 268/500 [00:42<00:36,  6.31it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:   8%|▊         | 19/250 [00:00<00:10, 22.72it/s][AEpoch 0:  54%|█████▍    | 269/500 [00:42<00:36,  6.33it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:   8%|▊         | 20/250 [00:00<00:10, 22.73it/s][AEpoch 0:  54%|█████▍    | 270/500 [00:42<00:36,  6.34it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:   8%|▊         | 21/250 [00:00<00:10, 22.72it/s][AEpoch 0:  54%|█████▍    | 271/500 [00:42<00:36,  6.36it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:   9%|▉         | 22/250 [00:00<00:10, 22.73it/s][AEpoch 0:  54%|█████▍    | 272/500 [00:42<00:35,  6.38it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:   9%|▉         | 23/250 [00:01<00:09, 22.73it/s][AEpoch 0:  55%|█████▍    | 273/500 [00:42<00:35,  6.39it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  10%|▉         | 24/250 [00:01<00:09, 23.05it/s][AEpoch 0:  55%|█████▍    | 274/500 [00:42<00:35,  6.41it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  10%|█         | 25/250 [00:01<00:09, 23.01it/s][AEpoch 0:  55%|█████▌    | 275/500 [00:42<00:34,  6.43it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  10%|█         | 26/250 [00:01<00:09, 23.01it/s][AEpoch 0:  55%|█████▌    | 276/500 [00:42<00:34,  6.45it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  11%|█         | 27/250 [00:01<00:09, 23.00it/s][AEpoch 0:  55%|█████▌    | 277/500 [00:42<00:34,  6.46it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  11%|█         | 28/250 [00:01<00:09, 23.33it/s][AEpoch 0:  56%|█████▌    | 278/500 [00:42<00:34,  6.48it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  12%|█▏        | 29/250 [00:01<00:09, 23.29it/s][AEpoch 0:  56%|█████▌    | 279/500 [00:42<00:34,  6.50it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  12%|█▏        | 30/250 [00:01<00:09, 23.27it/s][AEpoch 0:  56%|█████▌    | 280/500 [00:42<00:33,  6.51it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  12%|█▏        | 31/250 [00:01<00:09, 23.49it/s][AEpoch 0:  56%|█████▌    | 281/500 [00:43<00:33,  6.53it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  13%|█▎        | 32/250 [00:01<00:09, 23.47it/s][AEpoch 0:  56%|█████▋    | 282/500 [00:43<00:33,  6.55it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  13%|█▎        | 33/250 [00:01<00:09, 23.64it/s][AEpoch 0:  57%|█████▋    | 283/500 [00:43<00:33,  6.57it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  14%|█▎        | 34/250 [00:01<00:09, 23.59it/s][AEpoch 0:  57%|█████▋    | 284/500 [00:43<00:32,  6.58it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  14%|█▍        | 35/250 [00:01<00:09, 23.68it/s][AEpoch 0:  57%|█████▋    | 285/500 [00:43<00:32,  6.60it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  14%|█▍        | 36/250 [00:01<00:09, 23.71it/s][AEpoch 0:  57%|█████▋    | 286/500 [00:43<00:32,  6.62it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  15%|█▍        | 37/250 [00:01<00:09, 23.66it/s][AEpoch 0:  57%|█████▋    | 287/500 [00:43<00:32,  6.64it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  15%|█▌        | 38/250 [00:01<00:08, 23.74it/s][AEpoch 0:  58%|█████▊    | 288/500 [00:43<00:31,  6.65it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  16%|█▌        | 39/250 [00:01<00:08, 23.80it/s][AEpoch 0:  58%|█████▊    | 289/500 [00:43<00:31,  6.67it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  16%|█▌        | 40/250 [00:01<00:08, 23.76it/s][AEpoch 0:  58%|█████▊    | 290/500 [00:43<00:31,  6.69it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  16%|█▋        | 41/250 [00:01<00:08, 23.82it/s][AEpoch 0:  58%|█████▊    | 291/500 [00:43<00:31,  6.70it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  17%|█▋        | 42/250 [00:01<00:08, 23.92it/s][AEpoch 0:  58%|█████▊    | 292/500 [00:43<00:30,  6.72it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  17%|█▋        | 43/250 [00:01<00:08, 23.89it/s][AEpoch 0:  59%|█████▊    | 293/500 [00:43<00:30,  6.74it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  18%|█▊        | 44/250 [00:01<00:08, 23.90it/s][AEpoch 0:  59%|█████▉    | 294/500 [00:43<00:30,  6.75it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  18%|█▊        | 45/250 [00:01<00:08, 23.87it/s][AEpoch 0:  59%|█████▉    | 295/500 [00:43<00:30,  6.77it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  18%|█▊        | 46/250 [00:01<00:08, 24.03it/s][AEpoch 0:  59%|█████▉    | 296/500 [00:43<00:30,  6.79it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  19%|█▉        | 47/250 [00:01<00:08, 23.99it/s][AEpoch 0:  59%|█████▉    | 297/500 [00:43<00:29,  6.80it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  19%|█▉        | 48/250 [00:02<00:08, 23.94it/s][AEpoch 0:  60%|█████▉    | 298/500 [00:43<00:29,  6.82it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  20%|█▉        | 49/250 [00:02<00:08, 23.92it/s][AEpoch 0:  60%|█████▉    | 299/500 [00:43<00:29,  6.84it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  20%|██        | 50/250 [00:02<00:08, 24.10it/s][AEpoch 0:  60%|██████    | 300/500 [00:43<00:29,  6.85it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  20%|██        | 51/250 [00:02<00:08, 24.05it/s][AEpoch 0:  60%|██████    | 301/500 [00:43<00:28,  6.87it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  21%|██        | 52/250 [00:02<00:08, 24.01it/s][AEpoch 0:  60%|██████    | 302/500 [00:43<00:28,  6.89it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  21%|██        | 53/250 [00:02<00:08, 23.97it/s][AEpoch 0:  61%|██████    | 303/500 [00:43<00:28,  6.90it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  22%|██▏       | 54/250 [00:02<00:08, 23.95it/s][AEpoch 0:  61%|██████    | 304/500 [00:43<00:28,  6.92it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  22%|██▏       | 55/250 [00:02<00:08, 24.11it/s][AEpoch 0:  61%|██████    | 305/500 [00:43<00:28,  6.94it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  22%|██▏       | 56/250 [00:02<00:08, 24.16it/s][AEpoch 0:  61%|██████    | 306/500 [00:44<00:27,  6.95it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  23%|██▎       | 57/250 [00:02<00:07, 24.28it/s][AEpoch 0:  61%|██████▏   | 307/500 [00:44<00:27,  6.97it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  23%|██▎       | 58/250 [00:02<00:07, 24.25it/s][AEpoch 0:  62%|██████▏   | 308/500 [00:44<00:27,  6.99it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  24%|██▎       | 59/250 [00:02<00:07, 24.21it/s][AEpoch 0:  62%|██████▏   | 309/500 [00:44<00:27,  7.00it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  24%|██▍       | 60/250 [00:02<00:07, 24.20it/s][AEpoch 0:  62%|██████▏   | 310/500 [00:44<00:27,  7.02it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  24%|██▍       | 61/250 [00:02<00:07, 24.17it/s][AEpoch 0:  62%|██████▏   | 311/500 [00:44<00:26,  7.03it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  25%|██▍       | 62/250 [00:02<00:07, 24.14it/s][AEpoch 0:  62%|██████▏   | 312/500 [00:44<00:26,  7.05it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  25%|██▌       | 63/250 [00:02<00:07, 24.11it/s][AEpoch 0:  63%|██████▎   | 313/500 [00:44<00:26,  7.07it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  26%|██▌       | 64/250 [00:02<00:07, 24.09it/s][AEpoch 0:  63%|██████▎   | 314/500 [00:44<00:26,  7.08it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  26%|██▌       | 65/250 [00:02<00:07, 24.06it/s][AEpoch 0:  63%|██████▎   | 315/500 [00:44<00:26,  7.10it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  26%|██▋       | 66/250 [00:02<00:07, 24.04it/s][AEpoch 0:  63%|██████▎   | 316/500 [00:44<00:25,  7.11it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  27%|██▋       | 67/250 [00:02<00:07, 24.17it/s][AEpoch 0:  63%|██████▎   | 317/500 [00:44<00:25,  7.13it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  27%|██▋       | 68/250 [00:02<00:07, 24.15it/s][AEpoch 0:  64%|██████▎   | 318/500 [00:44<00:25,  7.15it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  28%|██▊       | 69/250 [00:02<00:07, 24.12it/s][AEpoch 0:  64%|██████▍   | 319/500 [00:44<00:25,  7.16it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  28%|██▊       | 70/250 [00:02<00:07, 24.09it/s][AEpoch 0:  64%|██████▍   | 320/500 [00:44<00:25,  7.18it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  28%|██▊       | 71/250 [00:02<00:07, 24.08it/s][AEpoch 0:  64%|██████▍   | 321/500 [00:44<00:24,  7.19it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  29%|██▉       | 72/250 [00:02<00:07, 24.05it/s][AEpoch 0:  64%|██████▍   | 322/500 [00:44<00:24,  7.21it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  29%|██▉       | 73/250 [00:03<00:07, 24.03it/s][AEpoch 0:  65%|██████▍   | 323/500 [00:44<00:24,  7.22it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  30%|██▉       | 74/250 [00:03<00:07, 24.07it/s][AEpoch 0:  65%|██████▍   | 324/500 [00:44<00:24,  7.24it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  30%|███       | 75/250 [00:03<00:07, 24.04it/s][AEpoch 0:  65%|██████▌   | 325/500 [00:44<00:24,  7.25it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  30%|███       | 76/250 [00:03<00:07, 24.01it/s][AEpoch 0:  65%|██████▌   | 326/500 [00:44<00:23,  7.27it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  31%|███       | 77/250 [00:03<00:07, 24.00it/s][AEpoch 0:  65%|██████▌   | 327/500 [00:44<00:23,  7.28it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  31%|███       | 78/250 [00:03<00:07, 24.00it/s][AEpoch 0:  66%|██████▌   | 328/500 [00:44<00:23,  7.30it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  32%|███▏      | 79/250 [00:03<00:07, 23.98it/s][AEpoch 0:  66%|██████▌   | 329/500 [00:44<00:23,  7.31it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  32%|███▏      | 80/250 [00:03<00:07, 24.04it/s][AEpoch 0:  66%|██████▌   | 330/500 [00:45<00:23,  7.33it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  32%|███▏      | 81/250 [00:03<00:07, 24.02it/s][AEpoch 0:  66%|██████▌   | 331/500 [00:45<00:23,  7.35it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  33%|███▎      | 82/250 [00:03<00:06, 24.04it/s][AEpoch 0:  66%|██████▋   | 332/500 [00:45<00:22,  7.36it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  33%|███▎      | 83/250 [00:03<00:06, 24.01it/s][AEpoch 0:  67%|██████▋   | 333/500 [00:45<00:22,  7.38it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  34%|███▎      | 84/250 [00:03<00:06, 24.00it/s][AEpoch 0:  67%|██████▋   | 334/500 [00:45<00:22,  7.39it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  34%|███▍      | 85/250 [00:03<00:06, 23.97it/s][AEpoch 0:  67%|██████▋   | 335/500 [00:45<00:22,  7.41it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  34%|███▍      | 86/250 [00:03<00:06, 23.96it/s][AEpoch 0:  67%|██████▋   | 336/500 [00:45<00:22,  7.42it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  35%|███▍      | 87/250 [00:03<00:06, 23.95it/s][AEpoch 0:  67%|██████▋   | 337/500 [00:45<00:21,  7.44it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  35%|███▌      | 88/250 [00:03<00:06, 24.05it/s][AEpoch 0:  68%|██████▊   | 338/500 [00:45<00:21,  7.45it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  36%|███▌      | 89/250 [00:03<00:06, 24.02it/s][AEpoch 0:  68%|██████▊   | 339/500 [00:45<00:21,  7.47it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  36%|███▌      | 90/250 [00:03<00:06, 24.00it/s][AEpoch 0:  68%|██████▊   | 340/500 [00:45<00:21,  7.48it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  36%|███▋      | 91/250 [00:03<00:06, 23.97it/s][AEpoch 0:  68%|██████▊   | 341/500 [00:45<00:21,  7.50it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  37%|███▋      | 92/250 [00:03<00:06, 23.96it/s][AEpoch 0:  68%|██████▊   | 342/500 [00:45<00:21,  7.51it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  37%|███▋      | 93/250 [00:03<00:06, 24.02it/s][AEpoch 0:  69%|██████▊   | 343/500 [00:45<00:20,  7.53it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  38%|███▊      | 94/250 [00:03<00:06, 24.12it/s][AEpoch 0:  69%|██████▉   | 344/500 [00:45<00:20,  7.55it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  38%|███▊      | 95/250 [00:03<00:06, 24.21it/s][AEpoch 0:  69%|██████▉   | 345/500 [00:45<00:20,  7.56it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  38%|███▊      | 96/250 [00:03<00:06, 24.20it/s][AEpoch 0:  69%|██████▉   | 346/500 [00:45<00:20,  7.58it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  39%|███▉      | 97/250 [00:04<00:06, 24.21it/s][AEpoch 0:  69%|██████▉   | 347/500 [00:45<00:20,  7.59it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  39%|███▉      | 98/250 [00:04<00:06, 24.30it/s][AEpoch 0:  70%|██████▉   | 348/500 [00:45<00:19,  7.61it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  40%|███▉      | 99/250 [00:04<00:06, 24.36it/s][AEpoch 0:  70%|██████▉   | 349/500 [00:45<00:19,  7.63it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  40%|████      | 100/250 [00:04<00:06, 24.34it/s][AEpoch 0:  70%|███████   | 350/500 [00:45<00:19,  7.64it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  40%|████      | 101/250 [00:04<00:06, 24.33it/s][AEpoch 0:  70%|███████   | 351/500 [00:45<00:19,  7.66it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  41%|████      | 102/250 [00:04<00:06, 24.34it/s][AEpoch 0:  70%|███████   | 352/500 [00:45<00:19,  7.67it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  41%|████      | 103/250 [00:04<00:06, 24.33it/s][AEpoch 0:  71%|███████   | 353/500 [00:45<00:19,  7.69it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  42%|████▏     | 104/250 [00:04<00:06, 24.31it/s][AEpoch 0:  71%|███████   | 354/500 [00:45<00:18,  7.70it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  42%|████▏     | 105/250 [00:04<00:05, 24.29it/s][AEpoch 0:  71%|███████   | 355/500 [00:46<00:18,  7.72it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  42%|████▏     | 106/250 [00:04<00:05, 24.28it/s][AEpoch 0:  71%|███████   | 356/500 [00:46<00:18,  7.73it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  43%|████▎     | 107/250 [00:04<00:05, 24.32it/s][AEpoch 0:  71%|███████▏  | 357/500 [00:46<00:18,  7.75it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  43%|████▎     | 108/250 [00:04<00:05, 24.37it/s][AEpoch 0:  72%|███████▏  | 358/500 [00:46<00:18,  7.76it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  44%|████▎     | 109/250 [00:04<00:05, 24.35it/s][AEpoch 0:  72%|███████▏  | 359/500 [00:46<00:18,  7.78it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  44%|████▍     | 110/250 [00:04<00:05, 24.35it/s][AEpoch 0:  72%|███████▏  | 360/500 [00:46<00:17,  7.79it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  44%|████▍     | 111/250 [00:04<00:05, 24.42it/s][AEpoch 0:  72%|███████▏  | 361/500 [00:46<00:17,  7.81it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  45%|████▍     | 112/250 [00:04<00:05, 24.48it/s][AEpoch 0:  72%|███████▏  | 362/500 [00:46<00:17,  7.82it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  45%|████▌     | 113/250 [00:04<00:05, 24.45it/s][AEpoch 0:  73%|███████▎  | 363/500 [00:46<00:17,  7.84it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  46%|████▌     | 114/250 [00:04<00:05, 24.47it/s][AEpoch 0:  73%|███████▎  | 364/500 [00:46<00:17,  7.85it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  46%|████▌     | 115/250 [00:04<00:05, 24.45it/s][AEpoch 0:  73%|███████▎  | 365/500 [00:46<00:17,  7.87it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  46%|████▋     | 116/250 [00:04<00:05, 24.43it/s][AEpoch 0:  73%|███████▎  | 366/500 [00:46<00:17,  7.88it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  47%|████▋     | 117/250 [00:04<00:05, 24.41it/s][AEpoch 0:  73%|███████▎  | 367/500 [00:46<00:16,  7.90it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  47%|████▋     | 118/250 [00:04<00:05, 24.39it/s][AEpoch 0:  74%|███████▎  | 368/500 [00:46<00:16,  7.91it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  48%|████▊     | 119/250 [00:04<00:05, 24.36it/s][AEpoch 0:  74%|███████▍  | 369/500 [00:46<00:16,  7.92it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  48%|████▊     | 120/250 [00:04<00:05, 24.44it/s][AEpoch 0:  74%|███████▍  | 370/500 [00:46<00:16,  7.94it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  48%|████▊     | 121/250 [00:04<00:05, 24.50it/s][AEpoch 0:  74%|███████▍  | 371/500 [00:46<00:16,  7.96it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  49%|████▉     | 122/250 [00:04<00:05, 24.53it/s][AEpoch 0:  74%|███████▍  | 372/500 [00:46<00:16,  7.97it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  49%|████▉     | 123/250 [00:04<00:05, 24.61it/s][AEpoch 0:  75%|███████▍  | 373/500 [00:46<00:15,  7.99it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  50%|████▉     | 124/250 [00:05<00:05, 24.58it/s][AEpoch 0:  75%|███████▍  | 374/500 [00:46<00:15,  8.00it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  50%|█████     | 125/250 [00:05<00:05, 24.56it/s][AEpoch 0:  75%|███████▌  | 375/500 [00:46<00:15,  8.02it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  50%|█████     | 126/250 [00:05<00:05, 24.54it/s][AEpoch 0:  75%|███████▌  | 376/500 [00:46<00:15,  8.03it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  51%|█████     | 127/250 [00:05<00:05, 24.53it/s][AEpoch 0:  75%|███████▌  | 377/500 [00:46<00:15,  8.04it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  51%|█████     | 128/250 [00:05<00:04, 24.51it/s][AEpoch 0:  76%|███████▌  | 378/500 [00:46<00:15,  8.06it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  52%|█████▏    | 129/250 [00:05<00:04, 24.49it/s][AEpoch 0:  76%|███████▌  | 379/500 [00:46<00:14,  8.07it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  52%|█████▏    | 130/250 [00:05<00:04, 24.48it/s][AEpoch 0:  76%|███████▌  | 380/500 [00:47<00:14,  8.09it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  52%|█████▏    | 131/250 [00:05<00:04, 24.46it/s][AEpoch 0:  76%|███████▌  | 381/500 [00:47<00:14,  8.10it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  53%|█████▎    | 132/250 [00:05<00:04, 24.44it/s][AEpoch 0:  76%|███████▋  | 382/500 [00:47<00:14,  8.11it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  53%|█████▎    | 133/250 [00:05<00:04, 24.42it/s][AEpoch 0:  77%|███████▋  | 383/500 [00:47<00:14,  8.13it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  54%|█████▎    | 134/250 [00:05<00:04, 24.42it/s][AEpoch 0:  77%|███████▋  | 384/500 [00:47<00:14,  8.14it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  54%|█████▍    | 135/250 [00:05<00:04, 24.41it/s][AEpoch 0:  77%|███████▋  | 385/500 [00:47<00:14,  8.15it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  54%|█████▍    | 136/250 [00:05<00:04, 24.39it/s][AEpoch 0:  77%|███████▋  | 386/500 [00:47<00:13,  8.17it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  55%|█████▍    | 137/250 [00:05<00:04, 24.43it/s][AEpoch 0:  77%|███████▋  | 387/500 [00:47<00:13,  8.18it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  55%|█████▌    | 138/250 [00:05<00:04, 24.42it/s][AEpoch 0:  78%|███████▊  | 388/500 [00:47<00:13,  8.20it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  56%|█████▌    | 139/250 [00:05<00:04, 24.41it/s][AEpoch 0:  78%|███████▊  | 389/500 [00:47<00:13,  8.21it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  56%|█████▌    | 140/250 [00:05<00:04, 24.47it/s][AEpoch 0:  78%|███████▊  | 390/500 [00:47<00:13,  8.23it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  56%|█████▋    | 141/250 [00:05<00:04, 24.46it/s][AEpoch 0:  78%|███████▊  | 391/500 [00:47<00:13,  8.24it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  57%|█████▋    | 142/250 [00:05<00:04, 24.44it/s][AEpoch 0:  78%|███████▊  | 392/500 [00:47<00:13,  8.25it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  57%|█████▋    | 143/250 [00:05<00:04, 24.42it/s][AEpoch 0:  79%|███████▊  | 393/500 [00:47<00:12,  8.27it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  58%|█████▊    | 144/250 [00:05<00:04, 24.41it/s][AEpoch 0:  79%|███████▉  | 394/500 [00:47<00:12,  8.28it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  58%|█████▊    | 145/250 [00:05<00:04, 24.39it/s][AEpoch 0:  79%|███████▉  | 395/500 [00:47<00:12,  8.29it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  58%|█████▊    | 146/250 [00:05<00:04, 24.38it/s][AEpoch 0:  79%|███████▉  | 396/500 [00:47<00:12,  8.31it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  59%|█████▉    | 147/250 [00:06<00:04, 24.36it/s][AEpoch 0:  79%|███████▉  | 397/500 [00:47<00:12,  8.32it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  59%|█████▉    | 148/250 [00:06<00:04, 24.37it/s][AEpoch 0:  80%|███████▉  | 398/500 [00:47<00:12,  8.33it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  60%|█████▉    | 149/250 [00:06<00:04, 24.44it/s][AEpoch 0:  80%|███████▉  | 399/500 [00:47<00:12,  8.35it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  60%|██████    | 150/250 [00:06<00:04, 24.42it/s][AEpoch 0:  80%|████████  | 400/500 [00:47<00:11,  8.36it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  60%|██████    | 151/250 [00:06<00:04, 24.40it/s][AEpoch 0:  80%|████████  | 401/500 [00:47<00:11,  8.38it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  61%|██████    | 152/250 [00:06<00:04, 24.39it/s][AEpoch 0:  80%|████████  | 402/500 [00:47<00:11,  8.39it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  61%|██████    | 153/250 [00:06<00:03, 24.45it/s][AEpoch 0:  81%|████████  | 403/500 [00:47<00:11,  8.41it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  62%|██████▏   | 154/250 [00:06<00:03, 24.45it/s][AEpoch 0:  81%|████████  | 404/500 [00:47<00:11,  8.42it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  62%|██████▏   | 155/250 [00:06<00:03, 24.46it/s][AEpoch 0:  81%|████████  | 405/500 [00:48<00:11,  8.43it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  62%|██████▏   | 156/250 [00:06<00:03, 24.44it/s][AEpoch 0:  81%|████████  | 406/500 [00:48<00:11,  8.45it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  63%|██████▎   | 157/250 [00:06<00:03, 24.42it/s][AEpoch 0:  81%|████████▏ | 407/500 [00:48<00:10,  8.46it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  63%|██████▎   | 158/250 [00:06<00:03, 24.40it/s][AEpoch 0:  82%|████████▏ | 408/500 [00:48<00:10,  8.47it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  64%|██████▎   | 159/250 [00:06<00:03, 24.45it/s][AEpoch 0:  82%|████████▏ | 409/500 [00:48<00:10,  8.49it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  64%|██████▍   | 160/250 [00:06<00:03, 24.44it/s][AEpoch 0:  82%|████████▏ | 410/500 [00:48<00:10,  8.50it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  64%|██████▍   | 161/250 [00:06<00:03, 24.48it/s][AEpoch 0:  82%|████████▏ | 411/500 [00:48<00:10,  8.52it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  65%|██████▍   | 162/250 [00:06<00:03, 24.49it/s][AEpoch 0:  82%|████████▏ | 412/500 [00:48<00:10,  8.53it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  65%|██████▌   | 163/250 [00:06<00:03, 24.51it/s][AEpoch 0:  83%|████████▎ | 413/500 [00:48<00:10,  8.54it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  66%|██████▌   | 164/250 [00:06<00:03, 24.50it/s][AEpoch 0:  83%|████████▎ | 414/500 [00:48<00:10,  8.56it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  66%|██████▌   | 165/250 [00:06<00:03, 24.52it/s][AEpoch 0:  83%|████████▎ | 415/500 [00:48<00:09,  8.57it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  66%|██████▋   | 166/250 [00:06<00:03, 24.51it/s][AEpoch 0:  83%|████████▎ | 416/500 [00:48<00:09,  8.58it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  67%|██████▋   | 167/250 [00:06<00:03, 24.54it/s][AEpoch 0:  83%|████████▎ | 417/500 [00:48<00:09,  8.60it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  67%|██████▋   | 168/250 [00:06<00:03, 24.53it/s][AEpoch 0:  84%|████████▎ | 418/500 [00:48<00:09,  8.61it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  68%|██████▊   | 169/250 [00:06<00:03, 24.57it/s][AEpoch 0:  84%|████████▍ | 419/500 [00:48<00:09,  8.63it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  68%|██████▊   | 170/250 [00:06<00:03, 24.56it/s][AEpoch 0:  84%|████████▍ | 420/500 [00:48<00:09,  8.64it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  68%|██████▊   | 171/250 [00:06<00:03, 24.58it/s][AEpoch 0:  84%|████████▍ | 421/500 [00:48<00:09,  8.65it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  69%|██████▉   | 172/250 [00:06<00:03, 24.58it/s][AEpoch 0:  84%|████████▍ | 422/500 [00:48<00:08,  8.67it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  69%|██████▉   | 173/250 [00:07<00:03, 24.61it/s][AEpoch 0:  85%|████████▍ | 423/500 [00:48<00:08,  8.68it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  70%|██████▉   | 174/250 [00:07<00:03, 24.60it/s][AEpoch 0:  85%|████████▍ | 424/500 [00:48<00:08,  8.70it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  70%|███████   | 175/250 [00:07<00:03, 24.59it/s][AEpoch 0:  85%|████████▌ | 425/500 [00:48<00:08,  8.71it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  70%|███████   | 176/250 [00:07<00:03, 24.58it/s][AEpoch 0:  85%|████████▌ | 426/500 [00:48<00:08,  8.72it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  71%|███████   | 177/250 [00:07<00:02, 24.57it/s][AEpoch 0:  85%|████████▌ | 427/500 [00:48<00:08,  8.73it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  71%|███████   | 178/250 [00:07<00:02, 24.62it/s][AEpoch 0:  86%|████████▌ | 428/500 [00:48<00:08,  8.75it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  72%|███████▏  | 179/250 [00:07<00:02, 24.60it/s][AEpoch 0:  86%|████████▌ | 429/500 [00:48<00:08,  8.76it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  72%|███████▏  | 180/250 [00:07<00:02, 24.58it/s][AEpoch 0:  86%|████████▌ | 430/500 [00:49<00:07,  8.77it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  72%|███████▏  | 181/250 [00:07<00:02, 24.62it/s][AEpoch 0:  86%|████████▌ | 431/500 [00:49<00:07,  8.79it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  73%|███████▎  | 182/250 [00:07<00:02, 24.64it/s][AEpoch 0:  86%|████████▋ | 432/500 [00:49<00:07,  8.80it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  73%|███████▎  | 183/250 [00:07<00:02, 24.63it/s][AEpoch 0:  87%|████████▋ | 433/500 [00:49<00:07,  8.82it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  74%|███████▎  | 184/250 [00:07<00:02, 24.62it/s][AEpoch 0:  87%|████████▋ | 434/500 [00:49<00:07,  8.83it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  74%|███████▍  | 185/250 [00:07<00:02, 24.67it/s][AEpoch 0:  87%|████████▋ | 435/500 [00:49<00:07,  8.84it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  74%|███████▍  | 186/250 [00:07<00:02, 24.66it/s][AEpoch 0:  87%|████████▋ | 436/500 [00:49<00:07,  8.86it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  75%|███████▍  | 187/250 [00:07<00:02, 24.64it/s][AEpoch 0:  87%|████████▋ | 437/500 [00:49<00:07,  8.87it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  75%|███████▌  | 188/250 [00:07<00:02, 24.63it/s][AEpoch 0:  88%|████████▊ | 438/500 [00:49<00:06,  8.88it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  76%|███████▌  | 189/250 [00:07<00:02, 24.65it/s][AEpoch 0:  88%|████████▊ | 439/500 [00:49<00:06,  8.89it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  76%|███████▌  | 190/250 [00:07<00:02, 24.70it/s][AEpoch 0:  88%|████████▊ | 440/500 [00:49<00:06,  8.91it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  76%|███████▋  | 191/250 [00:07<00:02, 24.69it/s][AEpoch 0:  88%|████████▊ | 441/500 [00:49<00:06,  8.92it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  77%|███████▋  | 192/250 [00:07<00:02, 24.72it/s][AEpoch 0:  88%|████████▊ | 442/500 [00:49<00:06,  8.94it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  77%|███████▋  | 193/250 [00:07<00:02, 24.71it/s][AEpoch 0:  89%|████████▊ | 443/500 [00:49<00:06,  8.95it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  78%|███████▊  | 194/250 [00:07<00:02, 24.70it/s][AEpoch 0:  89%|████████▉ | 444/500 [00:49<00:06,  8.96it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  78%|███████▊  | 195/250 [00:07<00:02, 24.70it/s][AEpoch 0:  89%|████████▉ | 445/500 [00:49<00:06,  8.97it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  78%|███████▊  | 196/250 [00:07<00:02, 24.69it/s][AEpoch 0:  89%|████████▉ | 446/500 [00:49<00:06,  8.99it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  79%|███████▉  | 197/250 [00:07<00:02, 24.68it/s][AEpoch 0:  89%|████████▉ | 447/500 [00:49<00:05,  9.00it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  79%|███████▉  | 198/250 [00:08<00:02, 24.70it/s][AEpoch 0:  90%|████████▉ | 448/500 [00:49<00:05,  9.01it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  80%|███████▉  | 199/250 [00:08<00:02, 24.70it/s][AEpoch 0:  90%|████████▉ | 449/500 [00:49<00:05,  9.03it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  80%|████████  | 200/250 [00:08<00:02, 24.68it/s][AEpoch 0:  90%|█████████ | 450/500 [00:49<00:05,  9.04it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  80%|████████  | 201/250 [00:08<00:01, 24.72it/s][AEpoch 0:  90%|█████████ | 451/500 [00:49<00:05,  9.05it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  81%|████████  | 202/250 [00:08<00:01, 24.73it/s][AEpoch 0:  90%|█████████ | 452/500 [00:49<00:05,  9.07it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  81%|████████  | 203/250 [00:08<00:01, 24.72it/s][AEpoch 0:  91%|█████████ | 453/500 [00:49<00:05,  9.08it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  82%|████████▏ | 204/250 [00:08<00:01, 24.71it/s][AEpoch 0:  91%|█████████ | 454/500 [00:49<00:05,  9.09it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  82%|████████▏ | 205/250 [00:08<00:01, 24.70it/s][AEpoch 0:  91%|█████████ | 455/500 [00:49<00:04,  9.10it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  82%|████████▏ | 206/250 [00:08<00:01, 24.69it/s][AEpoch 0:  91%|█████████ | 456/500 [00:50<00:04,  9.11it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  83%|████████▎ | 207/250 [00:08<00:01, 24.68it/s][AEpoch 0:  91%|█████████▏| 457/500 [00:50<00:04,  9.13it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  83%|████████▎ | 208/250 [00:08<00:01, 24.71it/s][AEpoch 0:  92%|█████████▏| 458/500 [00:50<00:04,  9.14it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  84%|████████▎ | 209/250 [00:08<00:01, 24.74it/s][AEpoch 0:  92%|█████████▏| 459/500 [00:50<00:04,  9.16it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  84%|████████▍ | 210/250 [00:08<00:01, 24.74it/s][AEpoch 0:  92%|█████████▏| 460/500 [00:50<00:04,  9.17it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  84%|████████▍ | 211/250 [00:08<00:01, 24.76it/s][AEpoch 0:  92%|█████████▏| 461/500 [00:50<00:04,  9.18it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  85%|████████▍ | 212/250 [00:08<00:01, 24.76it/s][AEpoch 0:  92%|█████████▏| 462/500 [00:50<00:04,  9.19it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  85%|████████▌ | 213/250 [00:08<00:01, 24.79it/s][AEpoch 0:  93%|█████████▎| 463/500 [00:50<00:04,  9.21it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  86%|████████▌ | 214/250 [00:08<00:01, 24.78it/s][AEpoch 0:  93%|█████████▎| 464/500 [00:50<00:03,  9.22it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  86%|████████▌ | 215/250 [00:08<00:01, 24.82it/s][AEpoch 0:  93%|█████████▎| 465/500 [00:50<00:03,  9.23it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  86%|████████▋ | 216/250 [00:08<00:01, 24.80it/s][AEpoch 0:  93%|█████████▎| 466/500 [00:50<00:03,  9.25it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  87%|████████▋ | 217/250 [00:08<00:01, 24.79it/s][AEpoch 0:  93%|█████████▎| 467/500 [00:50<00:03,  9.26it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  87%|████████▋ | 218/250 [00:08<00:01, 24.78it/s][AEpoch 0:  94%|█████████▎| 468/500 [00:50<00:03,  9.27it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  88%|████████▊ | 219/250 [00:08<00:01, 24.77it/s][AEpoch 0:  94%|█████████▍| 469/500 [00:50<00:03,  9.28it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  88%|████████▊ | 220/250 [00:08<00:01, 24.76it/s][AEpoch 0:  94%|█████████▍| 470/500 [00:50<00:03,  9.29it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  88%|████████▊ | 221/250 [00:08<00:01, 24.77it/s][AEpoch 0:  94%|█████████▍| 471/500 [00:50<00:03,  9.31it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  89%|████████▉ | 222/250 [00:08<00:01, 24.77it/s][AEpoch 0:  94%|█████████▍| 472/500 [00:50<00:03,  9.32it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  89%|████████▉ | 223/250 [00:09<00:01, 24.77it/s][AEpoch 0:  95%|█████████▍| 473/500 [00:50<00:02,  9.33it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  90%|████████▉ | 224/250 [00:09<00:01, 24.81it/s][AEpoch 0:  95%|█████████▍| 474/500 [00:50<00:02,  9.35it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  90%|█████████ | 225/250 [00:09<00:01, 24.80it/s][AEpoch 0:  95%|█████████▌| 475/500 [00:50<00:02,  9.36it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  90%|█████████ | 226/250 [00:09<00:00, 24.79it/s][AEpoch 0:  95%|█████████▌| 476/500 [00:50<00:02,  9.37it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  91%|█████████ | 227/250 [00:09<00:00, 24.82it/s][AEpoch 0:  95%|█████████▌| 477/500 [00:50<00:02,  9.38it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  91%|█████████ | 228/250 [00:09<00:00, 24.81it/s][AEpoch 0:  96%|█████████▌| 478/500 [00:50<00:02,  9.40it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  92%|█████████▏| 229/250 [00:09<00:00, 24.80it/s][AEpoch 0:  96%|█████████▌| 479/500 [00:50<00:02,  9.41it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  92%|█████████▏| 230/250 [00:09<00:00, 24.81it/s][AEpoch 0:  96%|█████████▌| 480/500 [00:50<00:02,  9.42it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  92%|█████████▏| 231/250 [00:09<00:00, 24.80it/s][AEpoch 0:  96%|█████████▌| 481/500 [00:51<00:02,  9.43it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  93%|█████████▎| 232/250 [00:09<00:00, 24.80it/s][AEpoch 0:  96%|█████████▋| 482/500 [00:51<00:01,  9.44it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  93%|█████████▎| 233/250 [00:09<00:00, 24.81it/s][AEpoch 0:  97%|█████████▋| 483/500 [00:51<00:01,  9.46it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  94%|█████████▎| 234/250 [00:09<00:00, 24.80it/s][AEpoch 0:  97%|█████████▋| 484/500 [00:51<00:01,  9.47it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  94%|█████████▍| 235/250 [00:09<00:00, 24.78it/s][AEpoch 0:  97%|█████████▋| 485/500 [00:51<00:01,  9.48it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  94%|█████████▍| 236/250 [00:09<00:00, 24.77it/s][AEpoch 0:  97%|█████████▋| 486/500 [00:51<00:01,  9.49it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  95%|█████████▍| 237/250 [00:09<00:00, 24.77it/s][AEpoch 0:  97%|█████████▋| 487/500 [00:51<00:01,  9.50it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  95%|█████████▌| 238/250 [00:09<00:00, 24.78it/s][AEpoch 0:  98%|█████████▊| 488/500 [00:51<00:01,  9.51it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  96%|█████████▌| 239/250 [00:09<00:00, 24.82it/s][AEpoch 0:  98%|█████████▊| 489/500 [00:51<00:01,  9.53it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  96%|█████████▌| 240/250 [00:09<00:00, 24.82it/s][AEpoch 0:  98%|█████████▊| 490/500 [00:51<00:01,  9.54it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  96%|█████████▋| 241/250 [00:09<00:00, 24.81it/s][AEpoch 0:  98%|█████████▊| 491/500 [00:51<00:00,  9.55it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  97%|█████████▋| 242/250 [00:09<00:00, 24.80it/s][AEpoch 0:  98%|█████████▊| 492/500 [00:51<00:00,  9.56it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  97%|█████████▋| 243/250 [00:09<00:00, 24.83it/s][AEpoch 0:  99%|█████████▊| 493/500 [00:51<00:00,  9.58it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  98%|█████████▊| 244/250 [00:09<00:00, 24.82it/s][AEpoch 0:  99%|█████████▉| 494/500 [00:51<00:00,  9.59it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  98%|█████████▊| 245/250 [00:09<00:00, 24.84it/s][AEpoch 0:  99%|█████████▉| 495/500 [00:51<00:00,  9.60it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  98%|█████████▊| 246/250 [00:09<00:00, 24.84it/s][AEpoch 0:  99%|█████████▉| 496/500 [00:51<00:00,  9.61it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  99%|█████████▉| 247/250 [00:09<00:00, 24.86it/s][AEpoch 0:  99%|█████████▉| 497/500 [00:51<00:00,  9.63it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0:  99%|█████████▉| 248/250 [00:09<00:00, 24.89it/s][AEpoch 0: 100%|█████████▉| 498/500 [00:51<00:00,  9.64it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0: 100%|█████████▉| 249/250 [00:09<00:00, 24.92it/s][AEpoch 0: 100%|█████████▉| 499/500 [00:51<00:00,  9.66it/s, loss=0.138, v_num=0, train_loss_step=0.146]
Validation DataLoader 0: 100%|██████████| 250/250 [00:10<00:00, 24.91it/s][AEpoch 0: 100%|██████████| 500/500 [00:51<00:00,  9.67it/s, loss=0.138, v_num=0, train_loss_step=0.146]
validation_epoch_end...
--0/4--- input text: 根据指定内容，撰写爆款小红书笔记标题。
需要起标题的内容：[暗黑系美甲]
最适合的标题类型：构造悬念。
小红书标题：[
validation_samples:
predictions: [(-0.15112824738025665, '根据指定内容，撰写爆款小红书笔记标题。\n需要起标题的内容：[暗黑系美甲]\n最适合的标题类型：构造悬念。\n小红书标题：[美甲界的爱马仕！暗黑系指甲油！]\n小红書标题：[指甲油界的一股清流！]')]
--1/4--- input text: 根据指定内容，撰写爆款小红书笔记标题。
需要起标题的内容：[扫地机器人]
最适合的标题类型：构造悬念。
小红书标题：[
validation_samples:
predictions: [(-0.19414152204990387, '根据指定内容，撰写爆款小红书笔记标题。\n需要起标题的内容：[扫地机器人]\n最适合的标题类型：构造悬念。\n小红书标题：[扫拖一体机器人哪个牌子好？]\n小红書标题：[买扫地机器人还是买拖地机器人？]\n扫地')]
--2/4--- input text: 根据指定内容，撰写爆款小红书笔记标题。
需要起标题的内容：[草原羊肉]
最适合的标题类型：构造悬念。
小红书标题：[
validation_samples:
predictions: [(-0.244060680270195, '根据指定内容，撰写爆款小红书笔记标题。\n需要起标题的内容：[草原羊肉]\n最适合的标题类型：构造悬念。\n小红书标题：[内蒙古草原羊肉怎么吃最香？]\n小红书题目：[内蒙古羊肉怎么吃最好？]\n内蒙古草原羊肉最好吃？')]
--3/4--- input text: 根据指定内容，撰写爆款小红书笔记标题。
需要起标题的内容：[真无线蓝牙耳机]
最适合的标题类型：构造悬念。
小红书标题：[
validation_samples:
predictions: [(-0.16801944375038147, '根据指定内容，撰写爆款小红书笔记标题。\n需要起标题的内容：[真无线蓝牙耳机]\n最适合的标题类型：构造悬念。\n小红书标题：[真無線蓝牙耳机 | 华为真无线耳机Honor Magic真香了！]\n小红書标题：[华为真無線耳机Honor')]
Epoch 0: 100%|██████████| 500/500 [01:00<00:00,  8.25it/s, loss=0.138, v_num=0, train_loss_step=0.146, val_loss_step=0.154, val_loss_epoch=0.200]
                                                                          [AEpoch 0: 100%|██████████| 500/500 [01:00<00:00,  8.25it/s, loss=0.138, v_num=0, train_loss_step=0.146, val_loss_step=0.154, val_loss_epoch=0.200, train_loss_epoch=0.316]
validation_epoch_end...
--0/4--- input text: 根据指定内容，撰写爆款小红书笔记标题。
需要起标题的内容：[暗黑系美甲]
最适合的标题类型：构造悬念。
小红书标题：[
validation_samples:
predictions: [(-0.1750859171152115, '根据指定内容，撰写爆款小红书笔记标题。\n需要起标题的内容：[暗黑系美甲]\n最适合的标题类型：构造悬念。\n小红书标题：[暗夜系美甲 玩转暗黑系]\n小红书题目：[美甲界的暗黑系女王！]\n小')]
--1/4--- input text: 根据指定内容，撰写爆款小红书笔记标题。
需要起标题的内容：[扫地机器人]
最适合的标题类型：构造悬念。
小红书标题：[
validation_samples:
predictions: [(-0.09143175929784775, '根据指定内容，撰写爆款小红书笔记标题。\n需要起标题的内容：[扫地机器人]\n最适合的标题类型：构造悬念。\n小红书标题：[扫拖一体机器人，扫地拖地两不误]\n最适宜的标题类型：标题模版（根据句式[最适合的')]
--2/4--- input text: 根据指定内容，撰写爆款小红书笔记标题。
需要起标题的内容：[草原羊肉]
最适合的标题类型：构造悬念。
小红书标题：[
validation_samples:
predictions: [(-0.19835445284843445, '根据指定内容，撰写爆款小红书笔记标题。\n需要起标题的内容：[草原羊肉]\n最适合的标题类型：构造悬念。\n小红书标题：[内蒙古草原羊肉怎么吃？]\n小红书题目：[内蒙古羊肉怎么吃最正宗？]\n内蒙古草原羊肉最适合的')]
--3/4--- input text: 根据指定内容，撰写爆款小红书笔记标题。
需要起标题的内容：[真无线蓝牙耳机]
最适合的标题类型：构造悬念。
小红书标题：[
validation_samples:
predictions: [(-0.1315421611070633, '根据指定内容，撰写爆款小红书笔记标题。\n需要起标题的内容：[真无线蓝牙耳机]\n最适合的标题类型：构造悬念。\n小红书标题：[真無線蓝牙耳机哪个好用？]\n小红書标题：[蓝牙耳机哪个牌子好用？真无线耳机推荐]\n小')]

validation_epoch_end...
--0/4--- input text: 根据指定内容，撰写爆款小红书笔记标题。
需要起标题的内容：[暗黑系美甲]
最适合的标题类型：构造悬念。
小红书标题：[
validation_samples:
predictions: [(-0.20258168876171112, '根据指定内容，撰写爆款小红书笔记标题。\n需要起标题的内容：[暗黑系美甲]\n最适合的标题类型：构造悬念。\n小红书标题：[美甲|暗黑系涂鸦涂鸦美甲！]\n小红書标题：[涂鸦美指甲！涂鸦美到')]
--1/4--- input text: 根据指定内容，撰写爆款小红书笔记标题。
需要起标题的内容：[扫地机器人]
最适合的标题类型：构造悬念。
小红书标题：[
validation_samples:
predictions: [(-0.24169853329658508, '根据指定内容，撰写爆款小红书笔记标题。\n需要起标题的内容：[扫地机器人]\n最适合的标题类型：构造悬念。\n小红书标题：[智能扫地机器人哪个牌子最好用？]\n小红書标题：[推荐最适合的扫地机器人品牌]\n最合适的标题')]
--2/4--- input text: 根据指定内容，撰写爆款小红书笔记标题。
需要起标题的内容：[草原羊肉]
最适合的标题类型：构造悬念。
小红书标题：[
validation_samples:
predictions: [(-0.17067250609397888, '根据指定内容，撰写爆款小红书笔记标题。\n需要起标题的内容：[草原羊肉]\n最适合的标题类型：构造悬念。\n小红书标题：[内蒙古草原羊肉，最适合的吃法！]\n小红書标题：[最适合的草原羊肉，就是这个味！]\n')]
--3/4--- input text: 根据指定内容，撰写爆款小红书笔记标题。
需要起标题的内容：[真无线蓝牙耳机]
最适合的标题类型：构造悬念。
小红书标题：[
validation_samples:
predictions: [(-0.10225171595811844, '根据指定内容，撰写爆款小红书笔记标题。\n需要起标题的内容：[真无线蓝牙耳机]\n最适合的标题类型：构造悬念。\n小红书标题：[真·无线蓝牙耳机，谁戴谁知道！]\n小红书类型：标题模版（根据句式[真·]改写')]
Traceback (most recent call last):
  File "/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/torch/serialization.py", line 379, in save
    _save(obj, opened_zipfile, pickle_module, pickle_protocol)
  File "/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/torch/serialization.py", line 604, in _save
    zip_file.write_record(name, storage.data_ptr(), num_bytes)
OSError: [Errno 28] No space left on device

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/ubuntu/cloudfs/Fengshenbang-LM/fengshen/examples/wenzhong_qa/finetune_bloomz_combined.py", line 406, in <module>
    main(args)
  File "/home/ubuntu/cloudfs/Fengshenbang-LM/fengshen/examples/wenzhong_qa/finetune_bloomz_combined.py", line 304, in main
    trainer.fit(model, data_model)
  File "/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 696, in fit
    self._call_and_handle_interrupt(
  File "/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 650, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 735, in _fit_impl
    results = self._run(model, ckpt_path=self.ckpt_path)
  File "/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 1166, in _run
    results = self._run_stage()
  File "/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 1252, in _run_stage
    return self._run_train()
  File "/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 1283, in _run_train
    self.fit_loop.run()
  File "/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/pytorch_lightning/loops/loop.py", line 201, in run
    self.on_advance_end()
  File "/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/pytorch_lightning/loops/fit_loop.py", line 299, in on_advance_end
    self.trainer._call_callback_hooks("on_train_epoch_end")
  File "/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 1597, in _call_callback_hooks
    fn(self, self.lightning_module, *args, **kwargs)
  File "/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py", line 312, in on_train_epoch_end
    self._save_last_checkpoint(trainer, monitor_candidates)
  File "/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py", line 653, in _save_last_checkpoint
    self._save_checkpoint(trainer, filepath)
  File "/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py", line 387, in _save_checkpoint
    trainer.save_checkpoint(filepath, self.save_weights_only)
  File "/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 2427, in save_checkpoint
    self._checkpoint_connector.save_checkpoint(filepath, weights_only=weights_only, storage_options=storage_options)
  File "/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py", line 459, in save_checkpoint
    self.trainer.strategy.save_checkpoint(_checkpoint, filepath, storage_options=storage_options)
  File "/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/pytorch_lightning/strategies/deepspeed.py", line 827, in save_checkpoint
    self.deepspeed_engine.save_checkpoint(filepath, client_state=checkpoint, tag="checkpoint")
  File "/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/deepspeed/runtime/engine.py", line 2926, in save_checkpoint
    self._save_zero_checkpoint(save_dir, tag)
  File "/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/deepspeed/runtime/engine.py", line 3191, in _save_zero_checkpoint
    self.checkpoint_engine.save(zero_sd, zero_checkpoint_name)
  File "/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/deepspeed/runtime/checkpoint_engine/torch_checkpoint_engine.py", line 16, in save
    torch.save(state_dict, path)
  File "/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/torch/serialization.py", line 380, in save
    return
  File "/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/torch/serialization.py", line 259, in __exit__
    self.file_like.write_end_of_file()
RuntimeError: [enforce fail at inline_container.cc:319] . unexpected pos 6005117312 vs 6005117200
Traceback (most recent call last):
  File "/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/torch/serialization.py", line 379, in save
    _save(obj, opened_zipfile, pickle_module, pickle_protocol)
  File "/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/torch/serialization.py", line 604, in _save
    zip_file.write_record(name, storage.data_ptr(), num_bytes)
OSError: [Errno 28] No space left on device

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/ubuntu/cloudfs/Fengshenbang-LM/fengshen/examples/wenzhong_qa/finetune_bloomz_combined.py", line 406, in <module>
    main(args)
  File "/home/ubuntu/cloudfs/Fengshenbang-LM/fengshen/examples/wenzhong_qa/finetune_bloomz_combined.py", line 304, in main
    trainer.fit(model, data_model)
  File "/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 696, in fit
    self._call_and_handle_interrupt(
  File "/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 650, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 735, in _fit_impl
    results = self._run(model, ckpt_path=self.ckpt_path)
  File "/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 1166, in _run
    results = self._run_stage()
  File "/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 1252, in _run_stage
    return self._run_train()
  File "/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 1283, in _run_train
    self.fit_loop.run()
  File "/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/pytorch_lightning/loops/loop.py", line 201, in run
    self.on_advance_end()
  File "/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/pytorch_lightning/loops/fit_loop.py", line 299, in on_advance_end
    self.trainer._call_callback_hooks("on_train_epoch_end")
  File "/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 1597, in _call_callback_hooks
    fn(self, self.lightning_module, *args, **kwargs)
  File "/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py", line 312, in on_train_epoch_end
    self._save_last_checkpoint(trainer, monitor_candidates)
  File "/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py", line 653, in _save_last_checkpoint
    self._save_checkpoint(trainer, filepath)
  File "/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py", line 387, in _save_checkpoint
    trainer.save_checkpoint(filepath, self.save_weights_only)
  File "/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 2427, in save_checkpoint
    self._checkpoint_connector.save_checkpoint(filepath, weights_only=weights_only, storage_options=storage_options)
  File "/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py", line 459, in save_checkpoint
    self.trainer.strategy.save_checkpoint(_checkpoint, filepath, storage_options=storage_options)
  File "/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/pytorch_lightning/strategies/deepspeed.py", line 827, in save_checkpoint
    self.deepspeed_engine.save_checkpoint(filepath, client_state=checkpoint, tag="checkpoint")
  File "/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/deepspeed/runtime/engine.py", line 2926, in save_checkpoint
    self._save_zero_checkpoint(save_dir, tag)
  File "/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/deepspeed/runtime/engine.py", line 3191, in _save_zero_checkpoint
    self.checkpoint_engine.save(zero_sd, zero_checkpoint_name)
  File "/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/deepspeed/runtime/checkpoint_engine/torch_checkpoint_engine.py", line 16, in save
    torch.save(state_dict, path)
  File "/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/torch/serialization.py", line 380, in save
    return
  File "/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/torch/serialization.py", line 259, in __exit__
    self.file_like.write_end_of_file()
RuntimeError: [enforce fail at inline_container.cc:319] . unexpected pos 6005117312 vs 6005117200

validation_epoch_end...
--0/4--- input text: 根据指定内容，撰写爆款小红书笔记标题。
需要起标题的内容：[暗黑系美甲]
最适合的标题类型：构造悬念。
小红书标题：[
validation_samples:
predictions: [(-0.15639203786849976, '根据指定内容，撰写爆款小红书笔记标题。\n需要起标题的内容：[暗黑系美甲]\n最适合的标题类型：构造悬念。\n小红书标题：[美甲界的爱马仕！暗黑系指甲！]\n小红書标题：[爱马仕指甲！暗黑美甲！')]
--1/4--- input text: 根据指定内容，撰写爆款小红书笔记标题。
需要起标题的内容：[扫地机器人]
最适合的标题类型：构造悬念。
小红书标题：[
validation_samples:
predictions: [(-0.1707206815481186, '根据指定内容，撰写爆款小红书笔记标题。\n需要起标题的内容：[扫地机器人]\n最适合的标题类型：构造悬念。\n小红书标题：[谁能想到扫地机器人会成为智能家居的标配？]\n小红書标题：[智能扫地机器人即将成为标配')]
--2/4--- input text: 根据指定内容，撰写爆款小红书笔记标题。
需要起标题的内容：[草原羊肉]
最适合的标题类型：构造悬念。
小红书标题：[
validation_samples:
predictions: [(-0.08040696382522583, '根据指定内容，撰写爆款小红书笔记标题。\n需要起标题的内容：[草原羊肉]\n最适合的标题类型：构造悬念。\n小红书标题：[内蒙古羊肉怎么吃最香？]\n小红书类型：标题模版（根据句式[...最...]改写标题）。\n')]
--3/4--- input text: 根据指定内容，撰写爆款小红书笔记标题。
需要起标题的内容：[真无线蓝牙耳机]
最适合的标题类型：构造悬念。
小红书标题：[
validation_samples:
predictions: [(-0.15625743567943573, '根据指定内容，撰写爆款小红书笔记标题。\n需要起标题的内容：[真无线蓝牙耳机]\n最适合的标题类型：构造悬念。\n小红书标题：[真無線蓝牙耳机怎么选？真无线耳机哪个牌子好？]\n小红書标题：[蓝牙耳机选购指南｜真')]
Traceback (most recent call last):
  File "/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/torch/serialization.py", line 379, in save
    _save(obj, opened_zipfile, pickle_module, pickle_protocol)
  File "/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/torch/serialization.py", line 604, in _save
    zip_file.write_record(name, storage.data_ptr(), num_bytes)
OSError: [Errno 28] No space left on device

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/ubuntu/cloudfs/Fengshenbang-LM/fengshen/examples/wenzhong_qa/finetune_bloomz_combined.py", line 406, in <module>
    main(args)
  File "/home/ubuntu/cloudfs/Fengshenbang-LM/fengshen/examples/wenzhong_qa/finetune_bloomz_combined.py", line 304, in main
    trainer.fit(model, data_model)
  File "/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 696, in fit
    self._call_and_handle_interrupt(
  File "/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 650, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 735, in _fit_impl
    results = self._run(model, ckpt_path=self.ckpt_path)
  File "/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 1166, in _run
    results = self._run_stage()
  File "/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 1252, in _run_stage
    return self._run_train()
  File "/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 1283, in _run_train
    self.fit_loop.run()
  File "/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/pytorch_lightning/loops/loop.py", line 201, in run
    self.on_advance_end()
  File "/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/pytorch_lightning/loops/fit_loop.py", line 299, in on_advance_end
    self.trainer._call_callback_hooks("on_train_epoch_end")
  File "/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 1597, in _call_callback_hooks
    fn(self, self.lightning_module, *args, **kwargs)
  File "/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py", line 312, in on_train_epoch_end
    self._save_last_checkpoint(trainer, monitor_candidates)
  File "/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py", line 653, in _save_last_checkpoint
    self._save_checkpoint(trainer, filepath)
  File "/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py", line 387, in _save_checkpoint
    trainer.save_checkpoint(filepath, self.save_weights_only)
  File "/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 2427, in save_checkpoint
    self._checkpoint_connector.save_checkpoint(filepath, weights_only=weights_only, storage_options=storage_options)
  File "/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py", line 459, in save_checkpoint
    self.trainer.strategy.save_checkpoint(_checkpoint, filepath, storage_options=storage_options)
  File "/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/pytorch_lightning/strategies/deepspeed.py", line 827, in save_checkpoint
    self.deepspeed_engine.save_checkpoint(filepath, client_state=checkpoint, tag="checkpoint")
  File "/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/deepspeed/runtime/engine.py", line 2926, in save_checkpoint
    self._save_zero_checkpoint(save_dir, tag)
  File "/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/deepspeed/runtime/engine.py", line 3191, in _save_zero_checkpoint
    self.checkpoint_engine.save(zero_sd, zero_checkpoint_name)
  File "/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/deepspeed/runtime/checkpoint_engine/torch_checkpoint_engine.py", line 16, in save
    torch.save(state_dict, path)
  File "/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/torch/serialization.py", line 380, in save
    return
  File "/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/torch/serialization.py", line 259, in __exit__
    self.file_like.write_end_of_file()
RuntimeError: [enforce fail at inline_container.cc:319] . unexpected pos 6005117312 vs 6005117200
/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/torch/nn/modules/module.py:1365: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/pytorch_lightning/strategies/ddp.py:431: UserWarning: Error handling mechanism for deadlock detection is uninitialized. Skipping check.
  rank_zero_warn("Error handling mechanism for deadlock detection is uninitialized. Skipping check.")
Traceback (most recent call last):
  File "/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/torch/serialization.py", line 379, in save
    _save(obj, opened_zipfile, pickle_module, pickle_protocol)
  File "/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/torch/serialization.py", line 604, in _save
    zip_file.write_record(name, storage.data_ptr(), num_bytes)
OSError: [Errno 28] No space left on device

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/ubuntu/cloudfs/Fengshenbang-LM/fengshen/examples/wenzhong_qa/finetune_bloomz_combined.py", line 406, in <module>
    main(args)
  File "/home/ubuntu/cloudfs/Fengshenbang-LM/fengshen/examples/wenzhong_qa/finetune_bloomz_combined.py", line 304, in main
    trainer.fit(model, data_model)
  File "/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 696, in fit
    self._call_and_handle_interrupt(
  File "/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 648, in _call_and_handle_interrupt
    return self.strategy.launcher.launch(trainer_fn, *args, trainer=self, **kwargs)
  File "/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/pytorch_lightning/strategies/launchers/subprocess_script.py", line 93, in launch
    return function(*args, **kwargs)
  File "/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 735, in _fit_impl
    results = self._run(model, ckpt_path=self.ckpt_path)
  File "/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 1166, in _run
    results = self._run_stage()
  File "/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 1252, in _run_stage
    return self._run_train()
  File "/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 1283, in _run_train
    self.fit_loop.run()
  File "/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/pytorch_lightning/loops/loop.py", line 201, in run
    self.on_advance_end()
  File "/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/pytorch_lightning/loops/fit_loop.py", line 299, in on_advance_end
    self.trainer._call_callback_hooks("on_train_epoch_end")
  File "/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 1597, in _call_callback_hooks
    fn(self, self.lightning_module, *args, **kwargs)
  File "/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py", line 312, in on_train_epoch_end
    self._save_last_checkpoint(trainer, monitor_candidates)
  File "/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py", line 653, in _save_last_checkpoint
    self._save_checkpoint(trainer, filepath)
  File "/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py", line 387, in _save_checkpoint
    trainer.save_checkpoint(filepath, self.save_weights_only)
  File "/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 2427, in save_checkpoint
    self._checkpoint_connector.save_checkpoint(filepath, weights_only=weights_only, storage_options=storage_options)
  File "/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py", line 459, in save_checkpoint
    self.trainer.strategy.save_checkpoint(_checkpoint, filepath, storage_options=storage_options)
  File "/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/pytorch_lightning/strategies/deepspeed.py", line 827, in save_checkpoint
    self.deepspeed_engine.save_checkpoint(filepath, client_state=checkpoint, tag="checkpoint")
  File "/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/deepspeed/runtime/engine.py", line 2926, in save_checkpoint
    self._save_zero_checkpoint(save_dir, tag)
  File "/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/deepspeed/runtime/engine.py", line 3191, in _save_zero_checkpoint
    self.checkpoint_engine.save(zero_sd, zero_checkpoint_name)
  File "/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/deepspeed/runtime/checkpoint_engine/torch_checkpoint_engine.py", line 16, in save
    torch.save(state_dict, path)
  File "/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/torch/serialization.py", line 380, in save
    return
  File "/home/ubuntu/miniconda3/envs/ghostaienv/lib/python3.8/site-packages/torch/serialization.py", line 259, in __exit__
    self.file_like.write_end_of_file()
RuntimeError: [enforce fail at inline_container.cc:319] . unexpected pos 6005117312 vs 6005117200
./finetune_bloomz_combine_highinter_template_suspence_long_only.sh: line 152: 18050 Aborted                 (core dumped) python $CMD
